{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "575a93c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-readers-obsidian in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (8.1.5)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: ipython in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 5)) (8.16.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.58.1)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: ipykernel in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 12)) (6.25.2)\n",
      "Requirement already satisfied: pyvis in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.3.2)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipywidgets->-r requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipywidgets->-r requirements.txt (line 3)) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/homebrew/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 3)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/homebrew/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 3)) (3.0.13)\n",
      "Requirement already satisfied: backcall in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: ollama>=0.4.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-llms-ollama->-r requirements.txt (line 9)) (0.4.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (8.3.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.3.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.5.8)\n",
      "Requirement already satisfied: psutil in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (6.3.3)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (3.1.5)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (4.0.1)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (3.4.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.11.11)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis->-r requirements.txt (line 13)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 12)) (3.10.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (10.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.5.18)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->-r requirements.txt (line 5)) (0.2.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (4.47.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.14.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.18.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from asttokens>=2.1.0->stack-data->ipython->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9954a1",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a66b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Charge les variables depuis le fichier .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_UP\")\n",
    "# Modifier ou ajouter une variable d'environnement\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f9e96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7bc2",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa4bc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a4b82",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d46a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9d70",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d810955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: As a data governance consultant, I don't have personal preferences or feelings. However, I can tell you about some popular data tools that are widely used in the industry for various purposes:\n",
      "\n",
      "1. **Collibra**: Known for its data governance and cataloging capabilities, Collibra helps organizations manage their data assets and ensure compliance with data policies.\n",
      "\n",
      "2. **Informatica**: Offers a suite of data management tools, including data integration, data quality, and master data management, which are essential for maintaining data governance.\n",
      "\n",
      "3. **Alation**: A data catalog tool that helps organizations discover, understand, and manage their data assets, promoting data literacy and governance.\n",
      "\n",
      "4. **Tableau**: While primarily a data visualization tool, Tableau can be integrated into data governance frameworks to ensure data is accurately represented and used.\n",
      "\n",
      "5. **Talend**: Provides data integration and data quality tools that support data governance by ensuring data accuracy and consistency.\n",
      "\n",
      "6. **Apache Atlas**: An open-source data governance and metadata management tool that helps organizations manage their data assets and lineage.\n",
      "\n",
      "Each of these tools has its strengths and is chosen based on the specific needs and goals of an organization’s data governance strategy.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47252b4e-eb58-453c-9e7d-bab5286ee296",
   "metadata": {},
   "source": [
    "# Load storage contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e8019-e150-4a60-b59d-cac7a4aebcba",
   "metadata": {},
   "source": [
    "## Load vector storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42c55a04-2b21-4c05-96fb-f0f9ce26bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"vector\"),\n",
    "    vector_store=SimpleVectorStore.from_persist_dir(\n",
    "        persist_dir=\"vector\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"vector\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b951a-9776-46da-9309-142acfc3f1dd",
   "metadata": {},
   "source": [
    "## Load knowledge graph storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a086ef48-3be3-4a12-b158-4ed50aa2b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"knowledge_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28317dfb",
   "metadata": {},
   "source": [
    "## Load onto graph storage context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db73d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"onto_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d278b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x289fcfc70>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x289ffbeb0>, vector_stores={'default': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={})), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x289fce6e0>, property_graph_store=None)\n"
     ]
    }
   ],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3f5b-f0fa-4e10-85fd-9ff7642de428",
   "metadata": {},
   "source": [
    "# Load index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e85a-8fca-4138-9ff9-fca4637a47e2",
   "metadata": {},
   "source": [
    "## Load vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68274006-61a7-42d7-9556-6ddae87d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "simple_index = load_index_from_storage(vector_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdab09-2c63-4e23-9ca3-79102db74cf0",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6c3e925-229f-4636-a7b7-73687a3aa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b32a3",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "887f57e4-8bc9-440b-a84c-0080cbd412e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31ff5f593784ac6a737b213b3a36781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "simple_rag_retriever = simple_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = simple_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f014fd60-81a4-4b7f-aef9-f545402e0fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Compréhension des Données**\n",
       "   - Identifier les sources de données disponibles (historique des prêts, informations démographiques, etc.).\n",
       "   - Définir l'objectif de la prédiction : comprendre les facteurs qui influencent le défaut de paiement.\n",
       "\n",
       "2. **Nettoyage des Données**\n",
       "   - Supprimer ou corriger les données inexactes ou les doublons.\n",
       "   - Remplir les données manquantes et uniformiser les formats (par exemple, dates).\n",
       "\n",
       "3. **Exploration des Données**\n",
       "   - Analyser les tendances et les relations entre les variables.\n",
       "   - Utiliser des visualisations pour identifier des modèles potentiels.\n",
       "\n",
       "4. **Sélection des Caractéristiques**\n",
       "   - Choisir les variables pertinentes qui pourraient influencer le défaut de paiement.\n",
       "   - Évaluer l'importance de chaque caractéristique à l'aide de techniques statistiques.\n",
       "\n",
       "5. **Modélisation Prédictive**\n",
       "   - Choisir un modèle de machine learning approprié (régression logistique, arbres de décision, etc.).\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "\n",
       "6. **Évaluation du Modèle**\n",
       "   - Tester le modèle sur l'ensemble de test pour évaluer sa précision.\n",
       "   - Utiliser des métriques comme l'accuracy, le rappel, et la précision pour mesurer la performance.\n",
       "\n",
       "7. **Interprétation et Communication**\n",
       "   - Interpréter les résultats pour comprendre les facteurs clés du défaut de paiement.\n",
       "   - Créer des visualisations claires pour communiquer les résultats aux parties prenantes.\n",
       "\n",
       "8. **Amélioration et Itération**\n",
       "   - Recueillir des retours des parties prenantes et ajuster le modèle si nécessaire.\n",
       "   - Répéter le processus pour améliorer la précision et la fiabilité des prédictions.\n",
       "\n",
       "9. **Mise en Œuvre**\n",
       "   - Intégrer le modèle dans le système de décision de l'entreprise.\n",
       "   - Assurer une surveillance continue pour maintenir la performance du modèle. \n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction de défaut de paiement en utilisant une approche méthodique et axée sur les données.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242ad8d-20fb-4126-9380-4d51c7e3fa32",
   "metadata": {},
   "source": [
    "## Load graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75e3c260-c349-43f0-b54c-6dac7a12586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "graph_index = load_index_from_storage(graph_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81c1e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8424ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 61\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0388bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 93 nodes and 61 edges\n",
      "Nodes: ['Exactitude', 'Justes et cohérentes', 'Complétude', 'Complet', 'Nettoyage', 'Erreurs', 'Normalisation', 'Formats', 'Florence nightingale', 'Infirmière britannique', \"Présentation visuelle de l'information\", 'Dataviz project', 'Relation', 'Bibliothèque', 'Description', 'Inputs', 'Visualisation', 'Objectif', 'Message', 'Volume', 'Quantité massive de données', 'Vélocité', 'Vitesse de génération de données', 'Base de données relationnelles', 'Données structurées', 'Outils comme sql', 'Base de données non relationnelles', 'Données non structurées', 'Tirer', 'Données', 'Format prédéfini', 'Texte libre', 'Claire et standardisée', 'Passer', 'Interprétation', 'Data visualisation', 'Données brutes en graphiques', 'Information claire et compréhensible', 'Processus', 'Exploitables', 'Dataviz', 'Data visualization', 'Interactive data visualization', 'Edward rolf tufte', 'Professor at yale university', 'Léonard de vinci des données\" by new york times', 'Théophile', 'Outil informatique', 'Ordinateur', 'Quantité de données phénoménales', 'Phase', 'Analyse', 'Anomalies', 'Utilise', 'Biais de perception', 'Computer interface', 'Utilisateur', 'Parcours', 'Les utilisateurs', 'Les données', 'La visualisation', 'La source', 'Traitement', 'Les dataviz', 'Tester', 'Parties prenantes', 'Hans rosling', 'Literary work', 'Sous-classe de', 'Agent', 'Art', 'Sélectionner visualisation', 'Mettre en évidence messages', 'Utilisateur final', \"Niveaux d'informations\", 'Personnes avec un handicap', 'Métadonnées', 'Date de la prise de vue', 'Résolution', \"L'art de la dataviz\", 'Trucs en connaissances', 'Service communication', 'Instinct', 'Réalité polarisée', 'Écart', 'Série temporelle', 'Graphique en ligne', 'Comparaisons entre catégories', 'Diagramme à barre ou camembert', 'Examiner', 'Fournies', 'Identifier', 'Relations entre les données']\n",
      "Edges: [('Exactitude', 'Justes et cohérentes'), ('Complétude', 'Complet'), ('Nettoyage', 'Erreurs'), ('Normalisation', 'Formats'), ('Florence nightingale', 'Infirmière britannique'), ('Florence nightingale', \"Présentation visuelle de l'information\"), ('Dataviz project', 'Relation'), ('Dataviz project', 'Bibliothèque'), ('Dataviz project', 'Description'), ('Inputs', 'Visualisation'), ('Visualisation', 'Objectif'), ('Visualisation', 'Message'), ('Volume', 'Quantité massive de données'), ('Vélocité', 'Vitesse de génération de données'), ('Base de données relationnelles', 'Données structurées'), ('Données structurées', 'Outils comme sql'), ('Base de données non relationnelles', 'Données non structurées'), ('Tirer', 'Données'), ('Données', 'Format prédéfini'), ('Données', 'Texte libre'), ('Données', 'Claire et standardisée'), ('Données', 'Processus'), ('Données', 'Phase'), ('Données', 'Les dataviz'), ('Données', 'Utilisateur final'), ('Données', 'Service communication'), ('Passer', 'Interprétation'), ('Data visualisation', 'Données brutes en graphiques'), ('Data visualisation', 'Information claire et compréhensible'), ('Processus', 'Exploitables'), ('Dataviz', 'Data visualization'), ('Dataviz', 'Interactive data visualization'), ('Edward rolf tufte', 'Professor at yale university'), ('Edward rolf tufte', 'Léonard de vinci des données\" by new york times'), ('Théophile', 'Outil informatique'), ('Ordinateur', 'Quantité de données phénoménales'), ('Analyse', 'Anomalies'), ('Utilise', 'Biais de perception'), ('Utilise', 'Computer interface'), ('Biais de perception', 'Literary work'), ('Utilisateur', 'Parcours'), ('Les utilisateurs', 'Les données'), ('Les utilisateurs', 'La visualisation'), ('Les données', 'La source'), ('Les données', 'Traitement'), ('Tester', 'Parties prenantes'), ('Hans rosling', 'Literary work'), ('Sous-classe de', 'Agent'), ('Art', 'Sélectionner visualisation'), ('Art', 'Mettre en évidence messages'), ('Utilisateur final', \"Niveaux d'informations\"), ('Utilisateur final', 'Personnes avec un handicap'), ('Métadonnées', 'Date de la prise de vue'), ('Métadonnées', 'Résolution'), (\"L'art de la dataviz\", 'Trucs en connaissances'), ('Instinct', 'Réalité polarisée'), ('Réalité polarisée', 'Écart'), ('Série temporelle', 'Graphique en ligne'), ('Comparaisons entre catégories', 'Diagramme à barre ou camembert'), ('Examiner', 'Fournies'), ('Identifier', 'Relations entre les données')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d6f30",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "330e38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e323b",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0dd0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a2626505394873a4545250f011924f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d841fcb-ff13-4c72-8dad-2e047817418e: ---\n",
      "utilise: \"[[dataviz]]\"\n",
      "sujet à: \"[[biais de perception]]\"\n",
      "---\n",
      "\n",
      "Réflexion ...\n",
      "> Querying with idx: 9d841fcb-ff13-4c72-8dad-2e047817418e: ---\n",
      "utilise: \"[[dataviz]]\"\n",
      "sujet à: \"[[biais de perception]]\"\n",
      "---\n",
      "\n",
      "Réflexion ...\n",
      "> Querying with idx: 9d841fcb-ff13-4c72-8dad-2e047817418e: ---\n",
      "utilise: \"[[dataviz]]\"\n",
      "sujet à: \"[[biais de perception]]\"\n",
      "---\n",
      "\n",
      "Réflexion ...\n",
      "> Querying with idx: 9d841fcb-ff13-4c72-8dad-2e047817418e: ---\n",
      "utilise: \"[[dataviz]]\"\n",
      "sujet à: \"[[biais de perception]]\"\n",
      "---\n",
      "\n",
      "Réflexion ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 5685f20a-aab2-401f-98da-8fa41aa50ab4: ---\n",
      "sous-classe de: \"[[agent]]\"\n",
      "partie de:\n",
      "  - \"[[système socio-technique]]\"\n",
      "...\n",
      "> Querying with idx: 5685f20a-aab2-401f-98da-8fa41aa50ab4: ---\n",
      "sous-classe de: \"[[agent]]\"\n",
      "partie de:\n",
      "  - \"[[système socio-technique]]\"\n",
      "...\n",
      "> Querying with idx: 5685f20a-aab2-401f-98da-8fa41aa50ab4: ---\n",
      "sous-classe de: \"[[agent]]\"\n",
      "partie de:\n",
      "  - \"[[système socio-technique]]\"\n",
      "...\n",
      "> Querying with idx: 5685f20a-aab2-401f-98da-8fa41aa50ab4: ---\n",
      "sous-classe de: \"[[agent]]\"\n",
      "partie de:\n",
      "  - \"[[système socio-technique]]\"\n",
      "...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: efc5155a-39d6-4e5b-9780-1a2d3cf519ac: ---\n",
      "author:\n",
      "  - \"[[Hans Rosling]]\"\n",
      "instance of: \"[[literary work]]\"\n",
      "documente...\n",
      "> Querying with idx: efc5155a-39d6-4e5b-9780-1a2d3cf519ac: ---\n",
      "author:\n",
      "  - \"[[Hans Rosling]]\"\n",
      "instance of: \"[[literary work]]\"\n",
      "documente...\n",
      "> Querying with idx: efc5155a-39d6-4e5b-9780-1a2d3cf519ac: ---\n",
      "author:\n",
      "  - \"[[Hans Rosling]]\"\n",
      "instance of: \"[[literary work]]\"\n",
      "documente...\n",
      "> Querying with idx: efc5155a-39d6-4e5b-9780-1a2d3cf519ac: ---\n",
      "author:\n",
      "  - \"[[Hans Rosling]]\"\n",
      "instance of: \"[[literary work]]\"\n",
      "documente...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_rag_retriever = graph_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1031a44-f06e-400f-beaa-2065beeee9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, il est essentiel de suivre un plan structuré qui inclut la collecte, le traitement et l'analyse des données. Voici un plan détaillé :\n",
       "\n",
       "1. **Collecte des données :**\n",
       "   - Rassembler des données historiques sur les clients, y compris les informations démographiques, les antécédents de crédit, les revenus, les dettes existantes, etc.\n",
       "   - Inclure des métadonnées pertinentes pour chaque client, comme la date de la demande de prêt et le type de prêt.\n",
       "\n",
       "2. **Préparation des données :**\n",
       "   - Organiser les données de manière claire et standardisée, idéalement dans un tableau avec des lignes et des colonnes.\n",
       "   - Nettoyer les données pour éliminer les valeurs manquantes ou aberrantes.\n",
       "   - Transformer les données non structurées, comme les notes de service ou les commentaires des clients, en données utilisables à l'aide de techniques de traitement du langage naturel.\n",
       "\n",
       "3. **Exploration des données :**\n",
       "   - Utiliser des visualisations de données pour comprendre les tendances et les distributions. Par exemple, des histogrammes pour la répartition des scores de crédit ou des diagrammes circulaires pour les proportions de défauts par catégorie de revenu.\n",
       "   - Identifier les biais de perception potentiels dans les données.\n",
       "\n",
       "4. **Modélisation :**\n",
       "   - Sélectionner un modèle de machine learning approprié pour la prédiction, comme la régression logistique, les arbres de décision ou les réseaux de neurones.\n",
       "   - Diviser les données en ensembles d'entraînement et de test pour évaluer la performance du modèle.\n",
       "\n",
       "5. **Évaluation du modèle :**\n",
       "   - Utiliser des métriques d'évaluation comme l'accuracy, le rappel, et la précision pour mesurer la performance du modèle.\n",
       "   - Ajuster les hyperparamètres du modèle pour améliorer les résultats.\n",
       "\n",
       "6. **Mise en œuvre :**\n",
       "   - Déployer le modèle dans un environnement de production où il peut être utilisé pour prédire les défauts de paiement en temps réel.\n",
       "   - Intégrer des éléments dynamiques pour permettre aux utilisateurs finaux d'explorer les prédictions et d'accéder à différents niveaux d'informations.\n",
       "\n",
       "7. **Surveillance et amélioration continue :**\n",
       "   - Surveiller la performance du modèle en continu et le mettre à jour avec de nouvelles données pour maintenir sa précision.\n",
       "   - Recueillir des retours d'expérience des utilisateurs finaux pour améliorer l'interface et l'accessibilité des résultats.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction de défauts de paiement de manière efficace et compréhensible pour tous les utilisateurs, y compris ceux avec des handicaps.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7541",
   "metadata": {},
   "source": [
    "## Load onto index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb203e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(persist_dir=\"onto_graph\")\n",
    "# Load the PropertyGraphIndex from the storage context\n",
    "\n",
    "onto_index = load_index_from_storage(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a182d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index.property_graph_store.save_networkx_graph(\n",
    "    name=\"OntoGraph.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4dcae",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bee17732",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95920ba",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c400086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3368a1a805454eb8b09176d8c44d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "onto_rag_retriever = onto_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "123366e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Collecte et Préparation des Données :**\n",
       "   - Rassembler les données historiques des clients, y compris les informations démographiques, les antécédents de crédit, les revenus, etc.\n",
       "   - Nettoyer les données pour éliminer les valeurs manquantes ou aberrantes.\n",
       "   - Transformer les données en un format approprié pour l'analyse, par exemple en normalisant les variables numériques.\n",
       "\n",
       "2. **Exploration des Données :**\n",
       "   - Utiliser des techniques de visualisation de données pour identifier les tendances et les relations entre les variables.\n",
       "   - Analyser les corrélations entre les caractéristiques des clients et les défauts de paiement.\n",
       "\n",
       "3. **Sélection des Caractéristiques :**\n",
       "   - Identifier les variables les plus pertinentes qui influencent le risque de défaut.\n",
       "   - Utiliser des techniques de réduction de dimensionnalité si nécessaire, comme l'analyse en composantes principales (PCA).\n",
       "\n",
       "4. **Choix du Modèle :**\n",
       "   - Sélectionner un modèle de machine learning approprié, tel que la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "   - Considérer l'utilisation de modèles plus avancés comme les réseaux de neurones ou les modèles de gradient boosting si les données sont volumineuses et complexes.\n",
       "\n",
       "5. **Entraînement et Validation du Modèle :**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "   - Valider le modèle en utilisant l'ensemble de test pour évaluer sa précision et sa capacité de généralisation.\n",
       "\n",
       "6. **Évaluation du Modèle :**\n",
       "   - Utiliser des métriques d'évaluation telles que l'accuracy, le F1-score, la précision, et le rappel pour mesurer la performance du modèle.\n",
       "   - Effectuer une analyse des erreurs pour comprendre les cas de défauts mal prédits.\n",
       "\n",
       "7. **Optimisation et Ajustement :**\n",
       "   - Ajuster les hyperparamètres du modèle pour améliorer sa performance.\n",
       "   - Envisager l'utilisation de techniques d'ensemble pour combiner plusieurs modèles et améliorer la robustesse des prédictions.\n",
       "\n",
       "8. **Déploiement et Surveillance :**\n",
       "   - Déployer le modèle dans un environnement de production pour prédire les défauts en temps réel.\n",
       "   - Mettre en place un système de surveillance pour suivre la performance du modèle et effectuer des mises à jour si nécessaire.\n",
       "\n",
       "9. **Interprétation et Communication des Résultats :**\n",
       "   - Présenter les résultats de manière compréhensible pour les parties prenantes, en utilisant des visualisations claires.\n",
       "   - Discuter des implications des prédictions pour la gestion des risques de crédit.\n",
       "\n",
       "Ce plan fournit une approche systématique pour développer un modèle prédictif de défaut de paiement sur un prêt bancaire.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b65be-955e-44db-942e-27e235384f19",
   "metadata": {},
   "source": [
    "# Visualize knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55ef03a2-2e7e-443d-865f-b6d991d16416",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9d58e14-0017-494f-98ec-ad8b30bf8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 61\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a113918c-f195-4c8c-b0f3-c85d7a6c5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 93 nodes and 61 edges\n",
      "Nodes: ['Exactitude', 'Justes et cohérentes', 'Complétude', 'Complet', 'Nettoyage', 'Erreurs', 'Normalisation', 'Formats', 'Florence nightingale', 'Infirmière britannique', \"Présentation visuelle de l'information\", 'Dataviz project', 'Relation', 'Bibliothèque', 'Description', 'Inputs', 'Visualisation', 'Objectif', 'Message', 'Volume', 'Quantité massive de données', 'Vélocité', 'Vitesse de génération de données', 'Base de données relationnelles', 'Données structurées', 'Outils comme sql', 'Base de données non relationnelles', 'Données non structurées', 'Tirer', 'Données', 'Format prédéfini', 'Texte libre', 'Claire et standardisée', 'Passer', 'Interprétation', 'Data visualisation', 'Données brutes en graphiques', 'Information claire et compréhensible', 'Processus', 'Exploitables', 'Dataviz', 'Data visualization', 'Interactive data visualization', 'Edward rolf tufte', 'Professor at yale university', 'Léonard de vinci des données\" by new york times', 'Théophile', 'Outil informatique', 'Ordinateur', 'Quantité de données phénoménales', 'Phase', 'Analyse', 'Anomalies', 'Utilise', 'Biais de perception', 'Computer interface', 'Utilisateur', 'Parcours', 'Les utilisateurs', 'Les données', 'La visualisation', 'La source', 'Traitement', 'Les dataviz', 'Tester', 'Parties prenantes', 'Hans rosling', 'Literary work', 'Sous-classe de', 'Agent', 'Art', 'Sélectionner visualisation', 'Mettre en évidence messages', 'Utilisateur final', \"Niveaux d'informations\", 'Personnes avec un handicap', 'Métadonnées', 'Date de la prise de vue', 'Résolution', \"L'art de la dataviz\", 'Trucs en connaissances', 'Service communication', 'Instinct', 'Réalité polarisée', 'Écart', 'Série temporelle', 'Graphique en ligne', 'Comparaisons entre catégories', 'Diagramme à barre ou camembert', 'Examiner', 'Fournies', 'Identifier', 'Relations entre les données']\n",
      "Edges: [('Exactitude', 'Justes et cohérentes'), ('Complétude', 'Complet'), ('Nettoyage', 'Erreurs'), ('Normalisation', 'Formats'), ('Florence nightingale', 'Infirmière britannique'), ('Florence nightingale', \"Présentation visuelle de l'information\"), ('Dataviz project', 'Relation'), ('Dataviz project', 'Bibliothèque'), ('Dataviz project', 'Description'), ('Inputs', 'Visualisation'), ('Visualisation', 'Objectif'), ('Visualisation', 'Message'), ('Volume', 'Quantité massive de données'), ('Vélocité', 'Vitesse de génération de données'), ('Base de données relationnelles', 'Données structurées'), ('Données structurées', 'Outils comme sql'), ('Base de données non relationnelles', 'Données non structurées'), ('Tirer', 'Données'), ('Données', 'Format prédéfini'), ('Données', 'Texte libre'), ('Données', 'Claire et standardisée'), ('Données', 'Processus'), ('Données', 'Phase'), ('Données', 'Les dataviz'), ('Données', 'Utilisateur final'), ('Données', 'Service communication'), ('Passer', 'Interprétation'), ('Data visualisation', 'Données brutes en graphiques'), ('Data visualisation', 'Information claire et compréhensible'), ('Processus', 'Exploitables'), ('Dataviz', 'Data visualization'), ('Dataviz', 'Interactive data visualization'), ('Edward rolf tufte', 'Professor at yale university'), ('Edward rolf tufte', 'Léonard de vinci des données\" by new york times'), ('Théophile', 'Outil informatique'), ('Ordinateur', 'Quantité de données phénoménales'), ('Analyse', 'Anomalies'), ('Utilise', 'Biais de perception'), ('Utilise', 'Computer interface'), ('Biais de perception', 'Literary work'), ('Utilisateur', 'Parcours'), ('Les utilisateurs', 'Les données'), ('Les utilisateurs', 'La visualisation'), ('Les données', 'La source'), ('Les données', 'Traitement'), ('Tester', 'Parties prenantes'), ('Hans rosling', 'Literary work'), ('Sous-classe de', 'Agent'), ('Art', 'Sélectionner visualisation'), ('Art', 'Mettre en évidence messages'), ('Utilisateur final', \"Niveaux d'informations\"), ('Utilisateur final', 'Personnes avec un handicap'), ('Métadonnées', 'Date de la prise de vue'), ('Métadonnées', 'Résolution'), (\"L'art de la dataviz\", 'Trucs en connaissances'), ('Instinct', 'Réalité polarisée'), ('Réalité polarisée', 'Écart'), ('Série temporelle', 'Graphique en ligne'), ('Comparaisons entre catégories', 'Diagramme à barre ou camembert'), ('Examiner', 'Fournies'), ('Identifier', 'Relations entre les données')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab94fc0-2080-4869-94a0-b013dc0fbd9d",
   "metadata": {},
   "source": [
    "# (Simple) Query the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c93bdbb-aaa4-4658-aecf-1cd7b5038ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a4b06bf5eb49578b2e2271e2576bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\"\n",
    "query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2a871b4-70c8-45ed-a8b9-b2aaa8d15a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Compréhension des Données**\n",
       "   - Identifier les sources de données disponibles (historique des prêts, informations démographiques, etc.).\n",
       "   - Définir l'objectif de la prédiction : identifier les clients à risque de défaut.\n",
       "\n",
       "2. **Nettoyage des Données**\n",
       "   - Supprimer ou corriger les données inexactes ou les doublons.\n",
       "   - Remplir les données manquantes et uniformiser les formats (par exemple, dates).\n",
       "\n",
       "3. **Exploration des Données**\n",
       "   - Analyser les tendances et les relations entre les variables.\n",
       "   - Utiliser des visualisations pour comprendre les distributions et les corrélations.\n",
       "\n",
       "4. **Sélection des Caractéristiques**\n",
       "   - Identifier les variables pertinentes qui influencent le risque de défaut (revenu, historique de crédit, etc.).\n",
       "   - Évaluer l'importance des caractéristiques à l'aide de techniques statistiques.\n",
       "\n",
       "5. **Modélisation Prédictive**\n",
       "   - Choisir un modèle de machine learning approprié (régression logistique, arbres de décision, etc.).\n",
       "   - Entraîner le modèle sur un ensemble de données d'entraînement.\n",
       "\n",
       "6. **Évaluation du Modèle**\n",
       "   - Tester le modèle sur un ensemble de données de test pour évaluer sa précision.\n",
       "   - Utiliser des métriques telles que l'accuracy, le rappel, et la précision.\n",
       "\n",
       "7. **Interprétation et Visualisation**\n",
       "   - Créer des visualisations pour expliquer les prédictions du modèle.\n",
       "   - Assurer que les visualisations sont compréhensibles pour les parties prenantes.\n",
       "\n",
       "8. **Mise en Production**\n",
       "   - Intégrer le modèle dans le système de décision de l'entreprise.\n",
       "   - Mettre en place un processus de surveillance pour évaluer la performance continue du modèle.\n",
       "\n",
       "9. **Retour d'Expérience et Amélioration**\n",
       "   - Recueillir des retours des utilisateurs finaux et des parties prenantes.\n",
       "   - Apporter des modifications et des améliorations au modèle si nécessaire. \n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction du défaut de paiement en utilisant une approche méthodique et centrée sur les données.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099031c-b137-468f-b20c-9c6fab1c4eb1",
   "metadata": {},
   "source": [
    "# (Simple) Query the knowledge graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8948dd2b-acd4-4621-a2d1-b45034a21007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5be1e72201646e894443bc079fab838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 36108fbc-9060-4bb3-89d2-4e67f9b72001: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 36108fbc-9060-4bb3-89d2-4e67f9b72001: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 36108fbc-9060-4bb3-89d2-4e67f9b72001: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 36108fbc-9060-4bb3-89d2-4e67f9b72001: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 507d5261-1965-46a5-8464-cde7a4a026ee: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "> Querying with idx: 507d5261-1965-46a5-8464-cde7a4a026ee: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "> Querying with idx: 507d5261-1965-46a5-8464-cde7a4a026ee: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "> Querying with idx: 507d5261-1965-46a5-8464-cde7a4a026ee: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan\"\n",
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff5382fd-1fc8-4faf-9356-c9bb3e478db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, il est essentiel de suivre un plan structuré qui inclut la préparation des données, la sélection d'un modèle de prédiction, et l'évaluation des résultats. Voici un plan détaillé :\n",
       "\n",
       "1. **Compréhension du problème et des données :**\n",
       "   - Définir clairement l'objectif de la prédiction : identifier les clients susceptibles de faire défaut.\n",
       "   - Identifier les caractéristiques des données disponibles, y compris les métadonnées pertinentes (par exemple, historique de crédit, revenu, etc.).\n",
       "\n",
       "2. **Préparation des données :**\n",
       "   - Nettoyer les données en supprimant ou corrigeant les inexactitudes et les doublons.\n",
       "   - Remplir les données manquantes et uniformiser les formats (par exemple, dates).\n",
       "   - Organiser les données de manière claire et standardisée, souvent dans un tableau avec des lignes et des colonnes.\n",
       "\n",
       "3. **Exploration et visualisation des données :**\n",
       "   - Utiliser des visualisations pour comprendre les tendances et les relations dans les données (par exemple, histogrammes pour la répartition des scores de crédit).\n",
       "   - Identifier les variables les plus pertinentes pour la prédiction.\n",
       "\n",
       "4. **Sélection et entraînement du modèle :**\n",
       "   - Choisir un modèle de machine learning adapté (par exemple, régression logistique, arbres de décision).\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "\n",
       "5. **Évaluation du modèle :**\n",
       "   - Tester le modèle sur l'ensemble de test pour évaluer sa précision et sa capacité à prédire les défauts.\n",
       "   - Utiliser des métriques d'évaluation comme l'accuracy, le rappel, et la précision.\n",
       "\n",
       "6. **Interprétation et communication des résultats :**\n",
       "   - Interpréter les résultats pour comprendre les facteurs qui influencent le défaut de paiement.\n",
       "   - Créer des visualisations compréhensibles pour communiquer les résultats aux parties prenantes, y compris les utilisateurs finaux.\n",
       "\n",
       "7. **Mise en œuvre et suivi :**\n",
       "   - Intégrer le modèle dans le système de décision de l'entreprise.\n",
       "   - Mettre en place un suivi pour évaluer la performance du modèle dans le temps et ajuster si nécessaire.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction de manière efficace et de s'assurer que les résultats sont fiables et utiles pour la prise de décision.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef119d0",
   "metadata": {},
   "source": [
    "# (Simple) Query the onto graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8db6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510361da69eb4fdeafd2355aa241a08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\"\n",
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=2,\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adcd4265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Collecte et Préparation des Données :**\n",
       "   - Rassembler les données historiques des clients, y compris les informations démographiques, les antécédents de crédit, les revenus, les dettes existantes, etc.\n",
       "   - Nettoyer les données pour éliminer les valeurs manquantes ou aberrantes.\n",
       "   - Créer des variables dérivées si nécessaire, comme le ratio dette/revenu.\n",
       "\n",
       "2. **Exploration des Données :**\n",
       "   - Utiliser des outils de visualisation de données pour explorer les relations entre les différentes variables et le défaut de paiement.\n",
       "   - Identifier les tendances et les modèles potentiels dans les données.\n",
       "\n",
       "3. **Sélection des Caractéristiques :**\n",
       "   - Choisir les caractéristiques les plus pertinentes qui influencent le défaut de paiement.\n",
       "   - Utiliser des techniques comme l'analyse de corrélation ou la sélection de caractéristiques basée sur l'importance.\n",
       "\n",
       "4. **Choix du Modèle :**\n",
       "   - Sélectionner un modèle de machine learning approprié, tel que la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "   - Justifier le choix du modèle en fonction de la nature des données et des objectifs de prédiction.\n",
       "\n",
       "5. **Entraînement et Validation du Modèle :**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "   - Valider le modèle en utilisant l'ensemble de test pour évaluer sa précision et sa capacité de généralisation.\n",
       "\n",
       "6. **Évaluation du Modèle :**\n",
       "   - Utiliser des métriques d'évaluation telles que l'accuracy, le F1-score, la précision, et le rappel pour mesurer la performance du modèle.\n",
       "   - Effectuer une analyse des erreurs pour comprendre les cas où le modèle se trompe.\n",
       "\n",
       "7. **Optimisation et Ajustement :**\n",
       "   - Ajuster les hyperparamètres du modèle pour améliorer sa performance.\n",
       "   - Envisager l'utilisation de techniques d'ensemble pour combiner plusieurs modèles et améliorer la précision.\n",
       "\n",
       "8. **Déploiement et Surveillance :**\n",
       "   - Déployer le modèle dans un environnement de production.\n",
       "   - Mettre en place un système de surveillance pour suivre la performance du modèle au fil du temps et effectuer des mises à jour si nécessaire.\n",
       "\n",
       "9. **Interprétation et Communication des Résultats :**\n",
       "   - Interpréter les résultats du modèle pour les parties prenantes.\n",
       "   - Utiliser des visualisations pour expliquer les prédictions et les facteurs influents.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction du défaut de paiement d'un client de manière méthodique et efficace.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582274ba",
   "metadata": {},
   "source": [
    "## (Node retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16db2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d79e2d335ff4fd9bcf26d234b39eaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Gérer qui peut avoir accès -> EXAMPLE_OF -> Ajout d'éléments dynamiques\n",
      "Ajout d'éléments dynamiques -> ENABLES -> créer une relation à la donnée\n",
      "\n",
      "Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explorer les [[données]] de différentes manières\n",
      "Permet de créer une relation à la donnée \n",
      "\n",
      "Exemple : \n",
      "- Gérer des filtres\n",
      "- Pouvoir afficher des détails\n",
      "- Avoir accès à différents niveaux d'informations, ou gérer qui peut avoir accès à quel niveau d'information \n",
      "\n",
      "#concept\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "théophile -> BELIEVES -> donnée liée à outil informatique\n",
      "\n",
      "> Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à la gueule et on me dit \"allez, fais moi une synthèse graphique\" et je suis paumé\n",
      "\n",
      "\n",
      "\n",
      "Que faire quand on se retrouve face à une montagne de [[données]]\n",
      "Quels sont les [[outils]] à disposition ? \n",
      "Quelles sont les bonnes pratiques pour réceptionner, gérer et exploiter des données ? \n",
      "\n",
      "\n",
      "Quelle est la part d'adaptation que l'on peut offrir quand on se retrouve face à quelque chose d'aussi rigoureux que la manipulation de données ?\n",
      "\n",
      "Pour moi (théophile) : la question de la donnée est intrinsèquement liée à la question de l'outil informatique puisque c'est comme ça qu'on la manipule aujourd'hui. Mais il y a aussi quelque chose de vertigineux dans le fait que l'outil avec lequel on manipule nos données (un ordinateur) manipule lui même une quantité de données phénoménales.\n",
      "\n",
      "La donnée des uns sera-t-elle la donnée des autres ? \n",
      "Comment assurer une transmission de la donnée ? \n",
      "Est-ce tout le point de la dataviz ? \n",
      "\n",
      "Dans la question de la dataviz et de son but il y a la question de l'interaction entre l'homme et la donnée\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "service communication -> UNDERSTANDS -> ce qui a mieux ou moins bien marché\n",
      "\n",
      "Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas de trucs qu'on sait pas trop comment définir en des connaissances et des idées et leur donner une application dans la vie courante.\n",
      "\n",
      "**Exemple :** Le service communication d'une entreprise analyse les données relatives à l'envoi d'une newsletter pour comprendre ce qui a mieux ou moins bien marché. Ils utilisent des outils qui mettent en forment les données et en produisent des évaluations, parfois même des interprétations.\n",
      "\n",
      "Pour comprendre les données, on cherche à analyser les [[Inférence]]s et trouver des relation dans notre tas d'informations.\n"
     ]
    }
   ],
   "source": [
    "retriever = onto_index.as_retriever(\n",
    "    include_text=True,  # include source text, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire ?\")\n",
    "\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a895520-d196-476f-b569-69a67484c120",
   "metadata": {},
   "source": [
    "# Have a real chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3764d-a084-4f36-9d8c-3613aa9fd835",
   "metadata": {},
   "source": [
    "## Set up the engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e55a2-a9a9-4c4e-89a4-c4dfba55ebe4",
   "metadata": {},
   "source": [
    "### Vector engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1581c90c-cf5a-40d3-81b0-086238068f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "vector_chat_engine = simple_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"You are a specialist about open models and you nurture a knowledge base on the subject\"\n",
    "        \"Be precise.\"\n",
    "        \".\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a1c22-111b-4793-8a3d-bd3eae7e3ec7",
   "metadata": {},
   "source": [
    "### Graph engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98b73cc2-0588-4b96-9aa2-1dfaf4cadb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897ec22",
   "metadata": {},
   "source": [
    "### Onto engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54d04e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto_chat_engine = onto_index.query_engine(\n",
    "#    chat_mode=\"condense_plus_context\",\n",
    "#    llm=llm\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e0a08-f6ff-4ee6-a165-9b9fd90621fa",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12804e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "709a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"You are a specialist about open models and you nurture a knowledge base on the subject\"\n",
    "        \"Be precise on concepts.\"\n",
    "        \" \"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "da3e3ebf-18dc-4bdc-87dc-58d0227e9c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2ee464ab1347119e19ea4ec3238a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91ebf21f-1990-4a4d-9c9a-868872f03042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "**Definition:**\n",
      "\n",
      "Open Access (OA) refers to the practice of providing unrestricted online access to scholarly research outputs, such as journal articles, conference papers, theses, and other academic publications. The primary goal of Open Access is to make research freely available to anyone with internet access, removing financial, legal, and technical barriers to the dissemination of knowledge.\n",
      "\n",
      "**Presentation:**\n",
      "\n",
      "Open Access is a transformative approach to academic publishing that challenges traditional subscription-based models. It encompasses a variety of models and practices, including self-archiving by authors, publication in Open Access journals, and institutional repositories. Open Access can be categorized into different types, such as \"Gold Open Access,\" where articles are published in OA journals, and \"Green Open Access,\" where authors deposit preprints or postprints in repositories. The movement is supported by a range of stakeholders, including researchers, academic institutions, funding bodies, and governments, all advocating for greater transparency and accessibility in scholarly communication.\n",
      "\n",
      "**Usage Description:**\n",
      "\n",
      "Open Access is utilized by researchers, educators, students, policymakers, and the general public. For researchers, it provides a platform to disseminate their work widely, increasing visibility and citation potential. Educators and students benefit from free access to a wealth of academic resources, enhancing teaching and learning experiences. Policymakers and practitioners can access the latest research findings to inform decision-making and practice. Open Access also empowers the public by providing access to scientific knowledge, fostering a more informed society.\n",
      "\n",
      "**Landscape:**\n",
      "\n",
      "The Open Access landscape is diverse and continually evolving. It includes a wide range of stakeholders, from individual researchers to large consortia and international organizations. Key players include Open Access publishers like PLOS and BioMed Central, institutional repositories, and advocacy groups such as the Scholarly Publishing and Academic Resources Coalition (SPARC). The landscape is shaped by policies and mandates from research funders and governments, which increasingly require publicly funded research to be made openly accessible. Technological advancements, such as digital repositories and open-source publishing platforms, also play a crucial role in facilitating Open Access.\n",
      "\n",
      "**History:**\n",
      "\n",
      "The Open Access movement emerged in the late 20th century as a response to the rising costs of journal subscriptions and the limitations of traditional publishing models. The Budapest Open Access Initiative in 2002 is often cited as a pivotal moment, where a group of scholars and advocates articulated a vision for free and open access to research. This was followed by other significant declarations, such as the Bethesda Statement on Open Access Publishing and the Berlin Declaration on Open Access to Knowledge. Over the years, the movement has gained momentum, driven by technological advancements, changing attitudes towards information sharing, and increasing support from funding agencies and academic institutions. Today, Open Access is a key component of the broader Open Science movement, which seeks to make all aspects of scientific research more transparent and accessible."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a056a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6660a81e-ad67-4d44-a86d-0ad7b77f626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_modele = \"\"\" \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c0e462e-d3ee-463a-8d49-f09dc2396b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the Open Access section model.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the Open Access section model.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the Open Access section model.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the Open Access section model.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5e22b502d941cc9a2c57e4d034e91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c86075ee-12c8-4b97-8b51-0c717fc4b1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "**Définition :**\n",
      "\n",
      "L'Open Business désigne un modèle d'entreprise qui prône la transparence, la collaboration et le partage d'informations au-delà des frontières organisationnelles traditionnelles. Ce concept repose sur l'idée que l'ouverture et la coopération peuvent stimuler l'innovation, améliorer l'efficacité et créer de la valeur pour toutes les parties prenantes, y compris les clients, les employés, les partenaires et la société dans son ensemble.\n",
      "\n",
      "**Présentation :**\n",
      "\n",
      "L'Open Business se distingue par son approche inclusive et participative, où les entreprises adoptent des pratiques de gestion ouvertes et collaboratives. Cela peut inclure le partage de données, l'adoption de logiciels open source, la co-création avec les clients et les partenaires, et la transparence dans la communication et la prise de décision. Les entreprises qui adoptent ce modèle cherchent à créer un écosystème dynamique où l'innovation est accélérée par l'échange libre d'idées et de ressources.\n",
      "\n",
      "**Description de l'utilisation :**\n",
      "\n",
      "L'Open Business est utilisé par des entreprises de toutes tailles et de tous secteurs pour stimuler l'innovation, améliorer la satisfaction des clients et renforcer l'engagement des employés. Les start-ups peuvent utiliser des plateformes open source pour développer rapidement de nouveaux produits, tandis que les grandes entreprises peuvent collaborer avec des partenaires externes pour explorer de nouveaux marchés. Les clients sont souvent impliqués dans le processus de développement de produits, ce qui permet de mieux répondre à leurs besoins et attentes. De plus, l'Open Business favorise une culture d'entreprise où les employés sont encouragés à partager leurs idées et à collaborer au-delà des silos organisationnels.\n",
      "\n",
      "**Paysage :**\n",
      "\n",
      "Le paysage de l'Open Business est varié et en constante évolution, englobant un large éventail d'industries et de pratiques. Des entreprises technologiques comme Red Hat et Mozilla, qui ont bâti leur modèle économique sur des logiciels open source, aux entreprises de biens de consommation qui impliquent les clients dans le développement de produits, l'Open Business prend de nombreuses formes. Les plateformes numériques et les réseaux sociaux jouent un rôle clé en facilitant la collaboration et le partage d'informations. De plus, des initiatives telles que les hackathons et les laboratoires d'innovation ouverte sont de plus en plus courantes, permettant aux entreprises de tirer parti de l'intelligence collective.\n",
      "\n",
      "**Histoire :**\n",
      "\n",
      "L'histoire de l'Open Business est étroitement liée à l'évolution des technologies de l'information et"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_response_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/chat_engine/types.py:325\u001b[0m, in \u001b[0;36mStreamingAgentChatResponse.print_response_stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_response_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_gen:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/ipykernel/iostream.py:580\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89855a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style used in the previous descriptions of Open Access and Open Business.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style used in the previous descriptions of Open Access and Open Business.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style used in the previous descriptions of Open Access and Open Business.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style used in the previous descriptions of Open Access and Open Business.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba8caac20d5408fa339d8f02d1e0386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0184336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "**Définition :**\n",
      "\n",
      "L'Open Banking désigne un système bancaire qui permet le partage sécurisé des données financières des clients entre différentes institutions financières et prestataires de services tiers, avec le consentement explicite des clients. Ce modèle vise à favoriser l'innovation, la concurrence et la transparence dans le secteur financier, en permettant le développement de nouveaux services et produits financiers adaptés aux besoins des consommateurs.\n",
      "\n",
      "**Présentation :**\n",
      "\n",
      "L'Open Banking se caractérise par l'utilisation d'interfaces de programmation d'applications (API) pour faciliter l'échange de données entre les banques et les prestataires de services tiers, tels que les fintechs. Ce modèle repose sur des principes de transparence, de sécurité et de consentement, garantissant que les clients ont le contrôle sur leurs données financières. L'Open Banking permet aux consommateurs d'accéder à une gamme plus large de services financiers, tels que la gestion de budget, les agrégateurs de comptes, et les solutions de paiement innovantes, tout en stimulant la concurrence entre les acteurs du secteur bancaire.\n",
      "\n",
      "**Description de l'utilisation :**\n",
      "\n",
      "Les pratiques d'Open Banking sont utilisées par les consommateurs pour bénéficier de services financiers plus personnalisés et compétitifs. En autorisant le partage de leurs données, les clients peuvent accéder à des outils de gestion financière qui leur offrent une vue d'ensemble de leurs finances, des recommandations personnalisées, et des solutions de paiement simplifiées. Les entreprises, quant à elles, peuvent exploiter l'Open Banking pour développer de nouveaux produits, améliorer l'expérience client, et optimiser leurs processus internes. Les banques traditionnelles peuvent également tirer parti de l'Open Banking pour collaborer avec des fintechs et innover plus rapidement.\n",
      "\n",
      "**Paysage :**\n",
      "\n",
      "Le paysage de l'Open Banking est marqué par une diversité d'acteurs, allant des grandes banques aux startups fintech, en passant par les régulateurs et les développeurs de technologies. Des initiatives réglementaires, telles que la directive européenne PSD2 (Payment Services Directive 2), ont joué un rôle crucial dans la promotion de l'Open Banking en établissant des normes pour le partage sécurisé des données. Les plateformes technologiques et les API sont au cœur de ce paysage, facilitant l'interopérabilité entre les différents acteurs. Le paysage est également influencé par des tendances telles que la numérisation croissante des services financiers et la demande accrue des consommateurs pour des solutions bancaires plus flexibles et transparentes.\n",
      "\n",
      "**Histoire :**\n",
      "\n",
      "L'histoire de l'Open Banking est relativement récente, mais elle s'inscrit dans un contexte plus large de transformation numérique du secteur financier. L'idée a commencé à prendre forme au début des années 2010, avec l'émergence des fintechs et la pression croissante pour moderniser les services bancaires. En 2018, l'entrée en vigueur de la directive PSD2 en Europe a marqué un tournant décisif, en établissant un cadre réglementaire pour l'Open Banking. Depuis lors, de nombreux pays ont adopté des initiatives similaires, favorisant l'essor de l'Open Banking à l'échelle mondiale. Aujourd'hui, l'Open Banking continue d'évoluer, façonné par les avancées technologiques, les attentes des consommateurs, et les dynamiques concurrentielles du secteur financier."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94929c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Based on your knowledge and your vision of the world, create a description of Open Design. It should include 5 parts: a definition, a presentation, a usage description, a landscape, and a history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Design. It should include 5 parts: a definition, a presentation, a usage description, a landscape, and a history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Design. It should include 5 parts: a definition, a presentation, a usage description, a landscape, and a history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Design. It should include 5 parts: a definition, a presentation, a usage description, a landscape, and a history. Please imitate the writing style of the previous sections.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0685bd21b5914561b660e9a6f2d7bf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Based on your knowledge and your vision of the world, create a description of Open Design. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8d5eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "**Définition :**\n",
      "\n",
      "L'Open Design désigne une approche de la conception qui encourage le partage libre et collaboratif des plans, des idées et des processus de création, permettant à quiconque de contribuer, modifier et utiliser les designs pour créer des produits ou des solutions. Ce modèle repose sur les principes de transparence, de collaboration et d'accessibilité, visant à démocratiser le processus de conception et à stimuler l'innovation collective.\n",
      "\n",
      "**Présentation :**\n",
      "\n",
      "L'Open Design se distingue par sa volonté de briser les barrières traditionnelles de la propriété intellectuelle et de favoriser une culture de partage et de co-création. En mettant à disposition des ressources de conception sous des licences ouvertes, les créateurs permettent à d'autres de s'inspirer, d'améliorer et de personnaliser les designs existants. Cette approche est souvent soutenue par des plateformes numériques qui facilitent la collaboration à distance et l'échange d'idées. L'Open Design s'inscrit dans une démarche de durabilité et d'inclusivité, cherchant à rendre le design accessible à tous, indépendamment des ressources ou des compétences techniques.\n",
      "\n",
      "**Description de l'utilisation :**\n",
      "\n",
      "Les pratiques d'Open Design sont utilisées par des designers, des ingénieurs, des artistes et des amateurs pour développer des produits et des solutions innovantes. En accédant à des designs ouverts, les utilisateurs peuvent adapter et personnaliser des créations pour répondre à des besoins spécifiques, qu'il s'agisse de mobilier, d'appareils électroniques, ou de vêtements. Les entreprises peuvent également exploiter l'Open Design pour accélérer le développement de produits, réduire les coûts de R&D, et impliquer les clients dans le processus de conception. Les communautés de makers et de fab labs sont des exemples emblématiques de l'utilisation de l'Open Design pour encourager l'innovation locale et participative.\n",
      "\n",
      "**Paysage :**\n",
      "\n",
      "Le paysage de l'Open Design est caractérisé par une diversité d'acteurs, allant des designers indépendants aux grandes entreprises, en passant par les plateformes collaboratives et les communautés en ligne. Des initiatives comme Thingiverse, OpenDesk, et Instructables jouent un rôle clé en fournissant des espaces où les créateurs peuvent partager et collaborer sur des projets de design. Le paysage est également influencé par des tendances telles que la montée en puissance de l'impression 3D, la fabrication numérique, et l'économie circulaire, qui encouragent des approches plus ouvertes et durables de la conception.\n",
      "\n",
      "**Histoire :**\n",
      "\n",
      "L'histoire de l'Open Design est étroitement liée à l'évolution des mouvements open source et DIY (Do It Yourself). Dans les années 2000, l'essor des technologies numériques et des plateformes en ligne a permis aux designers de partager plus facilement leurs créations et de collaborer à distance. Des projets pionniers, comme le RepRap (une imprimante 3D open source), ont démontré le potentiel de l'Open Design pour transformer la manière dont les produits sont conçus et fabriqués. Depuis lors, l'Open Design a gagné en popularité, soutenu par une communauté croissante de créateurs et d'innovateurs qui voient dans l'ouverture une voie vers une conception plus inclusive et durable. Aujourd'hui, l'Open Design continue d'évoluer, façonné par les avancées technologiques, les préoccupations environnementales, et les aspirations à une plus grande participation citoyenne dans le processus de création."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ffb78d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74a302-bb28-4bf8-9103-1f62750a5fc0",
   "metadata": {},
   "source": [
    "## Sum-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d81f7480-9d62-4952-948e-19e089d9da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = memory.get_all()\n",
    "\n",
    "# Assuming chat_history is available and contains your messages\n",
    "assistant_messages = [\n",
    "    message.content \n",
    "    for message in chat_history \n",
    "    if message.role == MessageRole.ASSISTANT  # Compare with the enum directly\n",
    "]\n",
    "\n",
    "\n",
    "output_filename = r\"/Users/arthursarazin/Documents/coreandgraphs/graphandopenmodels/output.md\"\n",
    "# Write to a Markdown file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for msg in assistant_messages:\n",
    "        f.write(msg + \"\\n\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
