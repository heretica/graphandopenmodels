{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "575a93c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-readers-obsidian in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (8.1.5)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: ipython in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 5)) (8.16.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.58.1)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: ipykernel in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 12)) (6.25.2)\n",
      "Requirement already satisfied: pyvis in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.3.2)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipywidgets->-r requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipywidgets->-r requirements.txt (line 3)) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/homebrew/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 3)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/homebrew/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 3)) (3.0.13)\n",
      "Requirement already satisfied: backcall in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: ollama>=0.4.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-llms-ollama->-r requirements.txt (line 9)) (0.4.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (8.3.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.3.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.5.8)\n",
      "Requirement already satisfied: psutil in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (6.3.3)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (3.1.5)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (4.0.1)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (3.4.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.11.11)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis->-r requirements.txt (line 13)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 12)) (3.10.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (10.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.5.18)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->-r requirements.txt (line 5)) (0.2.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (4.47.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.14.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.18.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from asttokens>=2.1.0->stack-data->ipython->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9954a1",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a66b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Charge les variables depuis le fichier .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_UP\")\n",
    "# Modifier ou ajouter une variable d'environnement\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f9e96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7bc2",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa4bc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a4b82",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d46a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9d70",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d810955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: As a data governance consultant, I don't have personal preferences or feelings. However, I can tell you about some popular data tools that are widely used in the industry for various purposes:\n",
      "\n",
      "1. **Collibra**: Known for its data governance and cataloging capabilities, Collibra helps organizations manage their data assets and ensure compliance with data policies.\n",
      "\n",
      "2. **Informatica**: Offers a suite of data management tools, including data integration, data quality, and master data management, which are essential for maintaining data governance.\n",
      "\n",
      "3. **Alation**: A data catalog tool that helps organizations discover, understand, and manage their data assets, promoting data literacy and governance.\n",
      "\n",
      "4. **Tableau**: While primarily a data visualization tool, Tableau can be integrated into data governance frameworks to ensure data is accurately represented and used.\n",
      "\n",
      "5. **Talend**: Provides data integration and data quality tools that support data governance by ensuring data accuracy and consistency.\n",
      "\n",
      "6. **Apache Atlas**: An open-source data governance and metadata management tool that helps organizations manage their data assets and lineage.\n",
      "\n",
      "Each of these tools has its strengths and is chosen based on the specific needs and goals of an organization’s data governance strategy.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47252b4e-eb58-453c-9e7d-bab5286ee296",
   "metadata": {},
   "source": [
    "# Load storage contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e8019-e150-4a60-b59d-cac7a4aebcba",
   "metadata": {},
   "source": [
    "## Load vector storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42c55a04-2b21-4c05-96fb-f0f9ce26bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"vector\"),\n",
    "    vector_store=SimpleVectorStore.from_persist_dir(\n",
    "        persist_dir=\"vector\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"vector\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b951a-9776-46da-9309-142acfc3f1dd",
   "metadata": {},
   "source": [
    "## Load knowledge graph storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a086ef48-3be3-4a12-b158-4ed50aa2b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"knowledge_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28317dfb",
   "metadata": {},
   "source": [
    "## Load onto graph storage context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db73d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"onto_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d278b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x289fcfc70>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x289ffbeb0>, vector_stores={'default': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={})), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x289fce6e0>, property_graph_store=None)\n"
     ]
    }
   ],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3f5b-f0fa-4e10-85fd-9ff7642de428",
   "metadata": {},
   "source": [
    "# Load index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e85a-8fca-4138-9ff9-fca4637a47e2",
   "metadata": {},
   "source": [
    "## Load vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68274006-61a7-42d7-9556-6ddae87d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "simple_index = load_index_from_storage(vector_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdab09-2c63-4e23-9ca3-79102db74cf0",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6c3e925-229f-4636-a7b7-73687a3aa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b32a3",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f57e4-8bc9-440b-a84c-0080cbd412e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31ff5f593784ac6a737b213b3a36781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "simple_rag_retriever = simple_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = simple_query_engine.query(\n",
    "    \"What is open model ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f014fd60-81a4-4b7f-aef9-f545402e0fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Compréhension des Données**\n",
       "   - Identifier les sources de données disponibles (historique des prêts, informations démographiques, etc.).\n",
       "   - Définir l'objectif de la prédiction : comprendre les facteurs qui influencent le défaut de paiement.\n",
       "\n",
       "2. **Nettoyage des Données**\n",
       "   - Supprimer ou corriger les données inexactes ou les doublons.\n",
       "   - Remplir les données manquantes et uniformiser les formats (par exemple, dates).\n",
       "\n",
       "3. **Exploration des Données**\n",
       "   - Analyser les tendances et les relations entre les variables.\n",
       "   - Utiliser des visualisations pour identifier des modèles potentiels.\n",
       "\n",
       "4. **Sélection des Caractéristiques**\n",
       "   - Choisir les variables pertinentes qui pourraient influencer le défaut de paiement.\n",
       "   - Évaluer l'importance de chaque caractéristique à l'aide de techniques statistiques.\n",
       "\n",
       "5. **Modélisation Prédictive**\n",
       "   - Choisir un modèle de machine learning approprié (régression logistique, arbres de décision, etc.).\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "\n",
       "6. **Évaluation du Modèle**\n",
       "   - Tester le modèle sur l'ensemble de test pour évaluer sa précision.\n",
       "   - Utiliser des métriques comme l'accuracy, le rappel, et la précision pour mesurer la performance.\n",
       "\n",
       "7. **Interprétation et Communication**\n",
       "   - Interpréter les résultats pour comprendre les facteurs clés du défaut de paiement.\n",
       "   - Créer des visualisations claires pour communiquer les résultats aux parties prenantes.\n",
       "\n",
       "8. **Amélioration et Itération**\n",
       "   - Recueillir des retours des parties prenantes et ajuster le modèle si nécessaire.\n",
       "   - Répéter le processus pour améliorer la précision et la fiabilité des prédictions.\n",
       "\n",
       "9. **Mise en Œuvre**\n",
       "   - Intégrer le modèle dans le système de décision de l'entreprise.\n",
       "   - Assurer une surveillance continue pour maintenir la performance du modèle. \n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction de défaut de paiement en utilisant une approche méthodique et axée sur les données.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242ad8d-20fb-4126-9380-4d51c7e3fa32",
   "metadata": {},
   "source": [
    "## Load graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75e3c260-c349-43f0-b54c-6dac7a12586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "graph_index = load_index_from_storage(graph_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81c1e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8424ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 61\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0388bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 93 nodes and 61 edges\n",
      "Nodes: ['Exactitude', 'Justes et cohérentes', 'Complétude', 'Complet', 'Nettoyage', 'Erreurs', 'Normalisation', 'Formats', 'Florence nightingale', 'Infirmière britannique', \"Présentation visuelle de l'information\", 'Dataviz project', 'Relation', 'Bibliothèque', 'Description', 'Inputs', 'Visualisation', 'Objectif', 'Message', 'Volume', 'Quantité massive de données', 'Vélocité', 'Vitesse de génération de données', 'Base de données relationnelles', 'Données structurées', 'Outils comme sql', 'Base de données non relationnelles', 'Données non structurées', 'Tirer', 'Données', 'Format prédéfini', 'Texte libre', 'Claire et standardisée', 'Passer', 'Interprétation', 'Data visualisation', 'Données brutes en graphiques', 'Information claire et compréhensible', 'Processus', 'Exploitables', 'Dataviz', 'Data visualization', 'Interactive data visualization', 'Edward rolf tufte', 'Professor at yale university', 'Léonard de vinci des données\" by new york times', 'Théophile', 'Outil informatique', 'Ordinateur', 'Quantité de données phénoménales', 'Phase', 'Analyse', 'Anomalies', 'Utilise', 'Biais de perception', 'Computer interface', 'Utilisateur', 'Parcours', 'Les utilisateurs', 'Les données', 'La visualisation', 'La source', 'Traitement', 'Les dataviz', 'Tester', 'Parties prenantes', 'Hans rosling', 'Literary work', 'Sous-classe de', 'Agent', 'Art', 'Sélectionner visualisation', 'Mettre en évidence messages', 'Utilisateur final', \"Niveaux d'informations\", 'Personnes avec un handicap', 'Métadonnées', 'Date de la prise de vue', 'Résolution', \"L'art de la dataviz\", 'Trucs en connaissances', 'Service communication', 'Instinct', 'Réalité polarisée', 'Écart', 'Série temporelle', 'Graphique en ligne', 'Comparaisons entre catégories', 'Diagramme à barre ou camembert', 'Examiner', 'Fournies', 'Identifier', 'Relations entre les données']\n",
      "Edges: [('Exactitude', 'Justes et cohérentes'), ('Complétude', 'Complet'), ('Nettoyage', 'Erreurs'), ('Normalisation', 'Formats'), ('Florence nightingale', 'Infirmière britannique'), ('Florence nightingale', \"Présentation visuelle de l'information\"), ('Dataviz project', 'Relation'), ('Dataviz project', 'Bibliothèque'), ('Dataviz project', 'Description'), ('Inputs', 'Visualisation'), ('Visualisation', 'Objectif'), ('Visualisation', 'Message'), ('Volume', 'Quantité massive de données'), ('Vélocité', 'Vitesse de génération de données'), ('Base de données relationnelles', 'Données structurées'), ('Données structurées', 'Outils comme sql'), ('Base de données non relationnelles', 'Données non structurées'), ('Tirer', 'Données'), ('Données', 'Format prédéfini'), ('Données', 'Texte libre'), ('Données', 'Claire et standardisée'), ('Données', 'Processus'), ('Données', 'Phase'), ('Données', 'Les dataviz'), ('Données', 'Utilisateur final'), ('Données', 'Service communication'), ('Passer', 'Interprétation'), ('Data visualisation', 'Données brutes en graphiques'), ('Data visualisation', 'Information claire et compréhensible'), ('Processus', 'Exploitables'), ('Dataviz', 'Data visualization'), ('Dataviz', 'Interactive data visualization'), ('Edward rolf tufte', 'Professor at yale university'), ('Edward rolf tufte', 'Léonard de vinci des données\" by new york times'), ('Théophile', 'Outil informatique'), ('Ordinateur', 'Quantité de données phénoménales'), ('Analyse', 'Anomalies'), ('Utilise', 'Biais de perception'), ('Utilise', 'Computer interface'), ('Biais de perception', 'Literary work'), ('Utilisateur', 'Parcours'), ('Les utilisateurs', 'Les données'), ('Les utilisateurs', 'La visualisation'), ('Les données', 'La source'), ('Les données', 'Traitement'), ('Tester', 'Parties prenantes'), ('Hans rosling', 'Literary work'), ('Sous-classe de', 'Agent'), ('Art', 'Sélectionner visualisation'), ('Art', 'Mettre en évidence messages'), ('Utilisateur final', \"Niveaux d'informations\"), ('Utilisateur final', 'Personnes avec un handicap'), ('Métadonnées', 'Date de la prise de vue'), ('Métadonnées', 'Résolution'), (\"L'art de la dataviz\", 'Trucs en connaissances'), ('Instinct', 'Réalité polarisée'), ('Réalité polarisée', 'Écart'), ('Série temporelle', 'Graphique en ligne'), ('Comparaisons entre catégories', 'Diagramme à barre ou camembert'), ('Examiner', 'Fournies'), ('Identifier', 'Relations entre les données')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d6f30",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "330e38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e323b",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a2626505394873a4545250f011924f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d841fcb-ff13-4c72-8dad-2e047817418e: ---\n",
      "utilise: \"[[dataviz]]\"\n",
      "sujet à: \"[[biais de perception]]\"\n",
      "---\n",
      "\n",
      "Réflexion ...\n",
      "> Querying with idx: 9d841fcb-ff13-4c72-8dad-2e047817418e: ---\n",
      "utilise: \"[[dataviz]]\"\n",
      "sujet à: \"[[biais de perception]]\"\n",
      "---\n",
      "\n",
      "Réflexion ...\n",
      "> Querying with idx: 9d841fcb-ff13-4c72-8dad-2e047817418e: ---\n",
      "utilise: \"[[dataviz]]\"\n",
      "sujet à: \"[[biais de perception]]\"\n",
      "---\n",
      "\n",
      "Réflexion ...\n",
      "> Querying with idx: 9d841fcb-ff13-4c72-8dad-2e047817418e: ---\n",
      "utilise: \"[[dataviz]]\"\n",
      "sujet à: \"[[biais de perception]]\"\n",
      "---\n",
      "\n",
      "Réflexion ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 5685f20a-aab2-401f-98da-8fa41aa50ab4: ---\n",
      "sous-classe de: \"[[agent]]\"\n",
      "partie de:\n",
      "  - \"[[système socio-technique]]\"\n",
      "...\n",
      "> Querying with idx: 5685f20a-aab2-401f-98da-8fa41aa50ab4: ---\n",
      "sous-classe de: \"[[agent]]\"\n",
      "partie de:\n",
      "  - \"[[système socio-technique]]\"\n",
      "...\n",
      "> Querying with idx: 5685f20a-aab2-401f-98da-8fa41aa50ab4: ---\n",
      "sous-classe de: \"[[agent]]\"\n",
      "partie de:\n",
      "  - \"[[système socio-technique]]\"\n",
      "...\n",
      "> Querying with idx: 5685f20a-aab2-401f-98da-8fa41aa50ab4: ---\n",
      "sous-classe de: \"[[agent]]\"\n",
      "partie de:\n",
      "  - \"[[système socio-technique]]\"\n",
      "...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: efc5155a-39d6-4e5b-9780-1a2d3cf519ac: ---\n",
      "author:\n",
      "  - \"[[Hans Rosling]]\"\n",
      "instance of: \"[[literary work]]\"\n",
      "documente...\n",
      "> Querying with idx: efc5155a-39d6-4e5b-9780-1a2d3cf519ac: ---\n",
      "author:\n",
      "  - \"[[Hans Rosling]]\"\n",
      "instance of: \"[[literary work]]\"\n",
      "documente...\n",
      "> Querying with idx: efc5155a-39d6-4e5b-9780-1a2d3cf519ac: ---\n",
      "author:\n",
      "  - \"[[Hans Rosling]]\"\n",
      "instance of: \"[[literary work]]\"\n",
      "documente...\n",
      "> Querying with idx: efc5155a-39d6-4e5b-9780-1a2d3cf519ac: ---\n",
      "author:\n",
      "  - \"[[Hans Rosling]]\"\n",
      "instance of: \"[[literary work]]\"\n",
      "documente...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_rag_retriever = graph_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"What is open model ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1031a44-f06e-400f-beaa-2065beeee9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, il est essentiel de suivre un plan structuré qui inclut la collecte, le traitement et l'analyse des données. Voici un plan détaillé :\n",
       "\n",
       "1. **Collecte des données :**\n",
       "   - Rassembler des données historiques sur les clients, y compris les informations démographiques, les antécédents de crédit, les revenus, les dettes existantes, etc.\n",
       "   - Inclure des métadonnées pertinentes pour chaque client, comme la date de la demande de prêt et le type de prêt.\n",
       "\n",
       "2. **Préparation des données :**\n",
       "   - Organiser les données de manière claire et standardisée, idéalement dans un tableau avec des lignes et des colonnes.\n",
       "   - Nettoyer les données pour éliminer les valeurs manquantes ou aberrantes.\n",
       "   - Transformer les données non structurées, comme les notes de service ou les commentaires des clients, en données utilisables à l'aide de techniques de traitement du langage naturel.\n",
       "\n",
       "3. **Exploration des données :**\n",
       "   - Utiliser des visualisations de données pour comprendre les tendances et les distributions. Par exemple, des histogrammes pour la répartition des scores de crédit ou des diagrammes circulaires pour les proportions de défauts par catégorie de revenu.\n",
       "   - Identifier les biais de perception potentiels dans les données.\n",
       "\n",
       "4. **Modélisation :**\n",
       "   - Sélectionner un modèle de machine learning approprié pour la prédiction, comme la régression logistique, les arbres de décision ou les réseaux de neurones.\n",
       "   - Diviser les données en ensembles d'entraînement et de test pour évaluer la performance du modèle.\n",
       "\n",
       "5. **Évaluation du modèle :**\n",
       "   - Utiliser des métriques d'évaluation comme l'accuracy, le rappel, et la précision pour mesurer la performance du modèle.\n",
       "   - Ajuster les hyperparamètres du modèle pour améliorer les résultats.\n",
       "\n",
       "6. **Mise en œuvre :**\n",
       "   - Déployer le modèle dans un environnement de production où il peut être utilisé pour prédire les défauts de paiement en temps réel.\n",
       "   - Intégrer des éléments dynamiques pour permettre aux utilisateurs finaux d'explorer les prédictions et d'accéder à différents niveaux d'informations.\n",
       "\n",
       "7. **Surveillance et amélioration continue :**\n",
       "   - Surveiller la performance du modèle en continu et le mettre à jour avec de nouvelles données pour maintenir sa précision.\n",
       "   - Recueillir des retours d'expérience des utilisateurs finaux pour améliorer l'interface et l'accessibilité des résultats.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction de défauts de paiement de manière efficace et compréhensible pour tous les utilisateurs, y compris ceux avec des handicaps.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7541",
   "metadata": {},
   "source": [
    "## Load onto index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb203e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(persist_dir=\"onto_graph\")\n",
    "# Load the PropertyGraphIndex from the storage context\n",
    "\n",
    "onto_index = load_index_from_storage(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a182d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index.property_graph_store.save_networkx_graph(\n",
    "    name=\"OntoGraph.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4dcae",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bee17732",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95920ba",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c400086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3368a1a805454eb8b09176d8c44d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "onto_rag_retriever = onto_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(\n",
    "    \"What is open model ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "123366e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Collecte et Préparation des Données :**\n",
       "   - Rassembler les données historiques des clients, y compris les informations démographiques, les antécédents de crédit, les revenus, etc.\n",
       "   - Nettoyer les données pour éliminer les valeurs manquantes ou aberrantes.\n",
       "   - Transformer les données en un format approprié pour l'analyse, par exemple en normalisant les variables numériques.\n",
       "\n",
       "2. **Exploration des Données :**\n",
       "   - Utiliser des techniques de visualisation de données pour identifier les tendances et les relations entre les variables.\n",
       "   - Analyser les corrélations entre les caractéristiques des clients et les défauts de paiement.\n",
       "\n",
       "3. **Sélection des Caractéristiques :**\n",
       "   - Identifier les variables les plus pertinentes qui influencent le risque de défaut.\n",
       "   - Utiliser des techniques de réduction de dimensionnalité si nécessaire, comme l'analyse en composantes principales (PCA).\n",
       "\n",
       "4. **Choix du Modèle :**\n",
       "   - Sélectionner un modèle de machine learning approprié, tel que la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "   - Considérer l'utilisation de modèles plus avancés comme les réseaux de neurones ou les modèles de gradient boosting si les données sont volumineuses et complexes.\n",
       "\n",
       "5. **Entraînement et Validation du Modèle :**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "   - Valider le modèle en utilisant l'ensemble de test pour évaluer sa précision et sa capacité de généralisation.\n",
       "\n",
       "6. **Évaluation du Modèle :**\n",
       "   - Utiliser des métriques d'évaluation telles que l'accuracy, le F1-score, la précision, et le rappel pour mesurer la performance du modèle.\n",
       "   - Effectuer une analyse des erreurs pour comprendre les cas de défauts mal prédits.\n",
       "\n",
       "7. **Optimisation et Ajustement :**\n",
       "   - Ajuster les hyperparamètres du modèle pour améliorer sa performance.\n",
       "   - Envisager l'utilisation de techniques d'ensemble pour combiner plusieurs modèles et améliorer la robustesse des prédictions.\n",
       "\n",
       "8. **Déploiement et Surveillance :**\n",
       "   - Déployer le modèle dans un environnement de production pour prédire les défauts en temps réel.\n",
       "   - Mettre en place un système de surveillance pour suivre la performance du modèle et effectuer des mises à jour si nécessaire.\n",
       "\n",
       "9. **Interprétation et Communication des Résultats :**\n",
       "   - Présenter les résultats de manière compréhensible pour les parties prenantes, en utilisant des visualisations claires.\n",
       "   - Discuter des implications des prédictions pour la gestion des risques de crédit.\n",
       "\n",
       "Ce plan fournit une approche systématique pour développer un modèle prédictif de défaut de paiement sur un prêt bancaire.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b65be-955e-44db-942e-27e235384f19",
   "metadata": {},
   "source": [
    "# Visualize knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55ef03a2-2e7e-443d-865f-b6d991d16416",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9d58e14-0017-494f-98ec-ad8b30bf8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 61\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a113918c-f195-4c8c-b0f3-c85d7a6c5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 93 nodes and 61 edges\n",
      "Nodes: ['Exactitude', 'Justes et cohérentes', 'Complétude', 'Complet', 'Nettoyage', 'Erreurs', 'Normalisation', 'Formats', 'Florence nightingale', 'Infirmière britannique', \"Présentation visuelle de l'information\", 'Dataviz project', 'Relation', 'Bibliothèque', 'Description', 'Inputs', 'Visualisation', 'Objectif', 'Message', 'Volume', 'Quantité massive de données', 'Vélocité', 'Vitesse de génération de données', 'Base de données relationnelles', 'Données structurées', 'Outils comme sql', 'Base de données non relationnelles', 'Données non structurées', 'Tirer', 'Données', 'Format prédéfini', 'Texte libre', 'Claire et standardisée', 'Passer', 'Interprétation', 'Data visualisation', 'Données brutes en graphiques', 'Information claire et compréhensible', 'Processus', 'Exploitables', 'Dataviz', 'Data visualization', 'Interactive data visualization', 'Edward rolf tufte', 'Professor at yale university', 'Léonard de vinci des données\" by new york times', 'Théophile', 'Outil informatique', 'Ordinateur', 'Quantité de données phénoménales', 'Phase', 'Analyse', 'Anomalies', 'Utilise', 'Biais de perception', 'Computer interface', 'Utilisateur', 'Parcours', 'Les utilisateurs', 'Les données', 'La visualisation', 'La source', 'Traitement', 'Les dataviz', 'Tester', 'Parties prenantes', 'Hans rosling', 'Literary work', 'Sous-classe de', 'Agent', 'Art', 'Sélectionner visualisation', 'Mettre en évidence messages', 'Utilisateur final', \"Niveaux d'informations\", 'Personnes avec un handicap', 'Métadonnées', 'Date de la prise de vue', 'Résolution', \"L'art de la dataviz\", 'Trucs en connaissances', 'Service communication', 'Instinct', 'Réalité polarisée', 'Écart', 'Série temporelle', 'Graphique en ligne', 'Comparaisons entre catégories', 'Diagramme à barre ou camembert', 'Examiner', 'Fournies', 'Identifier', 'Relations entre les données']\n",
      "Edges: [('Exactitude', 'Justes et cohérentes'), ('Complétude', 'Complet'), ('Nettoyage', 'Erreurs'), ('Normalisation', 'Formats'), ('Florence nightingale', 'Infirmière britannique'), ('Florence nightingale', \"Présentation visuelle de l'information\"), ('Dataviz project', 'Relation'), ('Dataviz project', 'Bibliothèque'), ('Dataviz project', 'Description'), ('Inputs', 'Visualisation'), ('Visualisation', 'Objectif'), ('Visualisation', 'Message'), ('Volume', 'Quantité massive de données'), ('Vélocité', 'Vitesse de génération de données'), ('Base de données relationnelles', 'Données structurées'), ('Données structurées', 'Outils comme sql'), ('Base de données non relationnelles', 'Données non structurées'), ('Tirer', 'Données'), ('Données', 'Format prédéfini'), ('Données', 'Texte libre'), ('Données', 'Claire et standardisée'), ('Données', 'Processus'), ('Données', 'Phase'), ('Données', 'Les dataviz'), ('Données', 'Utilisateur final'), ('Données', 'Service communication'), ('Passer', 'Interprétation'), ('Data visualisation', 'Données brutes en graphiques'), ('Data visualisation', 'Information claire et compréhensible'), ('Processus', 'Exploitables'), ('Dataviz', 'Data visualization'), ('Dataviz', 'Interactive data visualization'), ('Edward rolf tufte', 'Professor at yale university'), ('Edward rolf tufte', 'Léonard de vinci des données\" by new york times'), ('Théophile', 'Outil informatique'), ('Ordinateur', 'Quantité de données phénoménales'), ('Analyse', 'Anomalies'), ('Utilise', 'Biais de perception'), ('Utilise', 'Computer interface'), ('Biais de perception', 'Literary work'), ('Utilisateur', 'Parcours'), ('Les utilisateurs', 'Les données'), ('Les utilisateurs', 'La visualisation'), ('Les données', 'La source'), ('Les données', 'Traitement'), ('Tester', 'Parties prenantes'), ('Hans rosling', 'Literary work'), ('Sous-classe de', 'Agent'), ('Art', 'Sélectionner visualisation'), ('Art', 'Mettre en évidence messages'), ('Utilisateur final', \"Niveaux d'informations\"), ('Utilisateur final', 'Personnes avec un handicap'), ('Métadonnées', 'Date de la prise de vue'), ('Métadonnées', 'Résolution'), (\"L'art de la dataviz\", 'Trucs en connaissances'), ('Instinct', 'Réalité polarisée'), ('Réalité polarisée', 'Écart'), ('Série temporelle', 'Graphique en ligne'), ('Comparaisons entre catégories', 'Diagramme à barre ou camembert'), ('Examiner', 'Fournies'), ('Identifier', 'Relations entre les données')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab94fc0-2080-4869-94a0-b013dc0fbd9d",
   "metadata": {},
   "source": [
    "# (Simple) Query the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c93bdbb-aaa4-4658-aecf-1cd7b5038ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a4b06bf5eb49578b2e2271e2576bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"What is open model ?\"\n",
    "query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2a871b4-70c8-45ed-a8b9-b2aaa8d15a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Compréhension des Données**\n",
       "   - Identifier les sources de données disponibles (historique des prêts, informations démographiques, etc.).\n",
       "   - Définir l'objectif de la prédiction : identifier les clients à risque de défaut.\n",
       "\n",
       "2. **Nettoyage des Données**\n",
       "   - Supprimer ou corriger les données inexactes ou les doublons.\n",
       "   - Remplir les données manquantes et uniformiser les formats (par exemple, dates).\n",
       "\n",
       "3. **Exploration des Données**\n",
       "   - Analyser les tendances et les relations entre les variables.\n",
       "   - Utiliser des visualisations pour comprendre les distributions et les corrélations.\n",
       "\n",
       "4. **Sélection des Caractéristiques**\n",
       "   - Identifier les variables pertinentes qui influencent le risque de défaut (revenu, historique de crédit, etc.).\n",
       "   - Évaluer l'importance des caractéristiques à l'aide de techniques statistiques.\n",
       "\n",
       "5. **Modélisation Prédictive**\n",
       "   - Choisir un modèle de machine learning approprié (régression logistique, arbres de décision, etc.).\n",
       "   - Entraîner le modèle sur un ensemble de données d'entraînement.\n",
       "\n",
       "6. **Évaluation du Modèle**\n",
       "   - Tester le modèle sur un ensemble de données de test pour évaluer sa précision.\n",
       "   - Utiliser des métriques telles que l'accuracy, le rappel, et la précision.\n",
       "\n",
       "7. **Interprétation et Visualisation**\n",
       "   - Créer des visualisations pour expliquer les prédictions du modèle.\n",
       "   - Assurer que les visualisations sont compréhensibles pour les parties prenantes.\n",
       "\n",
       "8. **Mise en Production**\n",
       "   - Intégrer le modèle dans le système de décision de l'entreprise.\n",
       "   - Mettre en place un processus de surveillance pour évaluer la performance continue du modèle.\n",
       "\n",
       "9. **Retour d'Expérience et Amélioration**\n",
       "   - Recueillir des retours des utilisateurs finaux et des parties prenantes.\n",
       "   - Apporter des modifications et des améliorations au modèle si nécessaire. \n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction du défaut de paiement en utilisant une approche méthodique et centrée sur les données.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099031c-b137-468f-b20c-9c6fab1c4eb1",
   "metadata": {},
   "source": [
    "# (Simple) Query the knowledge graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8948dd2b-acd4-4621-a2d1-b45034a21007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5be1e72201646e894443bc079fab838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 6d25ed5c-5caa-4dd3-ae7d-04c06cda84f3: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: f10b2e04-b514-4033-96df-717cc6930850: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 2b1b16e8-1f8d-4751-8f1f-c12f3ca17453: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 7d6ba537-51b0-44a9-8ea8-4ec4533ddee8: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 832e5a71-16d0-457d-ba91-297f63d541f2: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 36108fbc-9060-4bb3-89d2-4e67f9b72001: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 36108fbc-9060-4bb3-89d2-4e67f9b72001: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 36108fbc-9060-4bb3-89d2-4e67f9b72001: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 36108fbc-9060-4bb3-89d2-4e67f9b72001: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 507d5261-1965-46a5-8464-cde7a4a026ee: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "> Querying with idx: 507d5261-1965-46a5-8464-cde7a4a026ee: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "> Querying with idx: 507d5261-1965-46a5-8464-cde7a4a026ee: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "> Querying with idx: 507d5261-1965-46a5-8464-cde7a4a026ee: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"What is open model ?\"\n",
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff5382fd-1fc8-4faf-9356-c9bb3e478db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, il est essentiel de suivre un plan structuré qui inclut la préparation des données, la sélection d'un modèle de prédiction, et l'évaluation des résultats. Voici un plan détaillé :\n",
       "\n",
       "1. **Compréhension du problème et des données :**\n",
       "   - Définir clairement l'objectif de la prédiction : identifier les clients susceptibles de faire défaut.\n",
       "   - Identifier les caractéristiques des données disponibles, y compris les métadonnées pertinentes (par exemple, historique de crédit, revenu, etc.).\n",
       "\n",
       "2. **Préparation des données :**\n",
       "   - Nettoyer les données en supprimant ou corrigeant les inexactitudes et les doublons.\n",
       "   - Remplir les données manquantes et uniformiser les formats (par exemple, dates).\n",
       "   - Organiser les données de manière claire et standardisée, souvent dans un tableau avec des lignes et des colonnes.\n",
       "\n",
       "3. **Exploration et visualisation des données :**\n",
       "   - Utiliser des visualisations pour comprendre les tendances et les relations dans les données (par exemple, histogrammes pour la répartition des scores de crédit).\n",
       "   - Identifier les variables les plus pertinentes pour la prédiction.\n",
       "\n",
       "4. **Sélection et entraînement du modèle :**\n",
       "   - Choisir un modèle de machine learning adapté (par exemple, régression logistique, arbres de décision).\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "\n",
       "5. **Évaluation du modèle :**\n",
       "   - Tester le modèle sur l'ensemble de test pour évaluer sa précision et sa capacité à prédire les défauts.\n",
       "   - Utiliser des métriques d'évaluation comme l'accuracy, le rappel, et la précision.\n",
       "\n",
       "6. **Interprétation et communication des résultats :**\n",
       "   - Interpréter les résultats pour comprendre les facteurs qui influencent le défaut de paiement.\n",
       "   - Créer des visualisations compréhensibles pour communiquer les résultats aux parties prenantes, y compris les utilisateurs finaux.\n",
       "\n",
       "7. **Mise en œuvre et suivi :**\n",
       "   - Intégrer le modèle dans le système de décision de l'entreprise.\n",
       "   - Mettre en place un suivi pour évaluer la performance du modèle dans le temps et ajuster si nécessaire.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction de manière efficace et de s'assurer que les résultats sont fiables et utiles pour la prise de décision.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef119d0",
   "metadata": {},
   "source": [
    "# (Simple) Query the onto graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8db6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510361da69eb4fdeafd2355aa241a08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"What is open model ?\"\n",
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=2,\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adcd4265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Collecte et Préparation des Données :**\n",
       "   - Rassembler les données historiques des clients, y compris les informations démographiques, les antécédents de crédit, les revenus, les dettes existantes, etc.\n",
       "   - Nettoyer les données pour éliminer les valeurs manquantes ou aberrantes.\n",
       "   - Créer des variables dérivées si nécessaire, comme le ratio dette/revenu.\n",
       "\n",
       "2. **Exploration des Données :**\n",
       "   - Utiliser des outils de visualisation de données pour explorer les relations entre les différentes variables et le défaut de paiement.\n",
       "   - Identifier les tendances et les modèles potentiels dans les données.\n",
       "\n",
       "3. **Sélection des Caractéristiques :**\n",
       "   - Choisir les caractéristiques les plus pertinentes qui influencent le défaut de paiement.\n",
       "   - Utiliser des techniques comme l'analyse de corrélation ou la sélection de caractéristiques basée sur l'importance.\n",
       "\n",
       "4. **Choix du Modèle :**\n",
       "   - Sélectionner un modèle de machine learning approprié, tel que la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "   - Justifier le choix du modèle en fonction de la nature des données et des objectifs de prédiction.\n",
       "\n",
       "5. **Entraînement et Validation du Modèle :**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "   - Valider le modèle en utilisant l'ensemble de test pour évaluer sa précision et sa capacité de généralisation.\n",
       "\n",
       "6. **Évaluation du Modèle :**\n",
       "   - Utiliser des métriques d'évaluation telles que l'accuracy, le F1-score, la précision, et le rappel pour mesurer la performance du modèle.\n",
       "   - Effectuer une analyse des erreurs pour comprendre les cas où le modèle se trompe.\n",
       "\n",
       "7. **Optimisation et Ajustement :**\n",
       "   - Ajuster les hyperparamètres du modèle pour améliorer sa performance.\n",
       "   - Envisager l'utilisation de techniques d'ensemble pour combiner plusieurs modèles et améliorer la précision.\n",
       "\n",
       "8. **Déploiement et Surveillance :**\n",
       "   - Déployer le modèle dans un environnement de production.\n",
       "   - Mettre en place un système de surveillance pour suivre la performance du modèle au fil du temps et effectuer des mises à jour si nécessaire.\n",
       "\n",
       "9. **Interprétation et Communication des Résultats :**\n",
       "   - Interpréter les résultats du modèle pour les parties prenantes.\n",
       "   - Utiliser des visualisations pour expliquer les prédictions et les facteurs influents.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction du défaut de paiement d'un client de manière méthodique et efficace.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582274ba",
   "metadata": {},
   "source": [
    "## (Node retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16db2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d79e2d335ff4fd9bcf26d234b39eaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Gérer qui peut avoir accès -> EXAMPLE_OF -> Ajout d'éléments dynamiques\n",
      "Ajout d'éléments dynamiques -> ENABLES -> créer une relation à la donnée\n",
      "\n",
      "Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explorer les [[données]] de différentes manières\n",
      "Permet de créer une relation à la donnée \n",
      "\n",
      "Exemple : \n",
      "- Gérer des filtres\n",
      "- Pouvoir afficher des détails\n",
      "- Avoir accès à différents niveaux d'informations, ou gérer qui peut avoir accès à quel niveau d'information \n",
      "\n",
      "#concept\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "théophile -> BELIEVES -> donnée liée à outil informatique\n",
      "\n",
      "> Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à la gueule et on me dit \"allez, fais moi une synthèse graphique\" et je suis paumé\n",
      "\n",
      "\n",
      "\n",
      "Que faire quand on se retrouve face à une montagne de [[données]]\n",
      "Quels sont les [[outils]] à disposition ? \n",
      "Quelles sont les bonnes pratiques pour réceptionner, gérer et exploiter des données ? \n",
      "\n",
      "\n",
      "Quelle est la part d'adaptation que l'on peut offrir quand on se retrouve face à quelque chose d'aussi rigoureux que la manipulation de données ?\n",
      "\n",
      "Pour moi (théophile) : la question de la donnée est intrinsèquement liée à la question de l'outil informatique puisque c'est comme ça qu'on la manipule aujourd'hui. Mais il y a aussi quelque chose de vertigineux dans le fait que l'outil avec lequel on manipule nos données (un ordinateur) manipule lui même une quantité de données phénoménales.\n",
      "\n",
      "La donnée des uns sera-t-elle la donnée des autres ? \n",
      "Comment assurer une transmission de la donnée ? \n",
      "Est-ce tout le point de la dataviz ? \n",
      "\n",
      "Dans la question de la dataviz et de son but il y a la question de l'interaction entre l'homme et la donnée\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "service communication -> UNDERSTANDS -> ce qui a mieux ou moins bien marché\n",
      "\n",
      "Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas de trucs qu'on sait pas trop comment définir en des connaissances et des idées et leur donner une application dans la vie courante.\n",
      "\n",
      "**Exemple :** Le service communication d'une entreprise analyse les données relatives à l'envoi d'une newsletter pour comprendre ce qui a mieux ou moins bien marché. Ils utilisent des outils qui mettent en forment les données et en produisent des évaluations, parfois même des interprétations.\n",
      "\n",
      "Pour comprendre les données, on cherche à analyser les [[Inférence]]s et trouver des relation dans notre tas d'informations.\n"
     ]
    }
   ],
   "source": [
    "retriever = onto_index.as_retriever(\n",
    "    include_text=True,  # include source text, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"What is open model ?\")\n",
    "\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a895520-d196-476f-b569-69a67484c120",
   "metadata": {},
   "source": [
    "# Have a real chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3764d-a084-4f36-9d8c-3613aa9fd835",
   "metadata": {},
   "source": [
    "## Set up the engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e55a2-a9a9-4c4e-89a4-c4dfba55ebe4",
   "metadata": {},
   "source": [
    "### Vector engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1581c90c-cf5a-40d3-81b0-086238068f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "vector_chat_engine = simple_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"You are a specialist about open models and you nurture a knowledge base on the subject\"\n",
    "        \"Be precise.\"\n",
    "        \".\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a1c22-111b-4793-8a3d-bd3eae7e3ec7",
   "metadata": {},
   "source": [
    "### Graph engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98b73cc2-0588-4b96-9aa2-1dfaf4cadb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897ec22",
   "metadata": {},
   "source": [
    "### Onto engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54d04e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto_chat_engine = onto_index.query_engine(\n",
    "#    chat_mode=\"condense_plus_context\",\n",
    "#    llm=llm\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e0a08-f6ff-4ee6-a165-9b9fd90621fa",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12804e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "709a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"You are a specialist about open models and you nurture a knowledge base on the subject\"\n",
    "        \"Be precise on concepts.\"\n",
    "        \" \"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da3e3ebf-18dc-4bdc-87dc-58d0227e9c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36bc9943d7f4a7eb88ff57953e4c8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: 87ca8359-7aa1-4fac-9e8a-f92fdb9222e4: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 6e223f50-3373-4f5a-8528-fde6a339033c: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Based on your knowledge and your vision of the world, create a description of Open Access. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "91ebf21f-1990-4a4d-9c9a-868872f03042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "### Definition\n",
      "Open Access (OA) refers to the practice of providing unrestricted online access to scholarly research outputs, such as journal articles, conference papers, theses, and book chapters. The primary goal of Open Access is to make research freely available to anyone with internet access, thereby promoting the dissemination and exchange of knowledge without financial, legal, or technical barriers.\n",
      "\n",
      "### Presentation\n",
      "Open Access is a transformative approach to scholarly publishing that challenges traditional subscription-based models. It is characterized by the removal of paywalls and the provision of free access to research outputs. Open Access can be achieved through various models, including the \"Gold\" model, where articles are published in open access journals, and the \"Green\" model, where authors self-archive their work in institutional or subject repositories. Hybrid models also exist, where subscription journals offer open access options for individual articles upon payment of an article processing charge (APC).\n",
      "\n",
      "### Usage Description\n",
      "Open Access is utilized by researchers, educators, policymakers, and the general public to access the latest scientific findings without cost barriers. Researchers benefit from increased visibility and citation of their work, while educators can incorporate the latest research into their teaching materials. Policymakers and practitioners can access evidence-based research to inform decision-making and practice. Open Access also supports interdisciplinary collaboration by making research accessible across different fields and regions.\n",
      "\n",
      "### Landscape\n",
      "The Open Access landscape is diverse and continually evolving. It includes a wide range of stakeholders, such as academic institutions, funding agencies, publishers, and libraries. Major initiatives and mandates from organizations like the European Commission, the National Institutes of Health (NIH), and the Plan S coalition have significantly influenced the adoption of Open Access policies. The landscape is also shaped by the development of open access repositories, platforms, and tools that facilitate the sharing and discovery of research outputs.\n",
      "\n",
      "### History\n",
      "The concept of Open Access emerged in the late 20th century as a response to the rising costs of journal subscriptions and the desire to democratize access to knowledge. The Budapest Open Access Initiative in 2002 is often cited as a pivotal moment in the Open Access movement, as it articulated a clear vision and strategy for achieving open access to scholarly literature. Since then, numerous declarations, such as the Berlin Declaration on Open Access to Knowledge in the Sciences and Humanities (2003), have further advanced the cause. Over the years, technological advancements and the growing emphasis on open science have accelerated the adoption of Open Access, making it a central component of modern scholarly communication."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5a056a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6660a81e-ad67-4d44-a86d-0ad7b77f626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_modele = \"\"\" \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9c0e462e-d3ee-463a-8d49-f09dc2396b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Imitate the writing style of the Open Access section model.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Imitate the writing style of the Open Access section model.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Imitate the writing style of the Open Access section model.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Imitate the writing style of the Open Access section model.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d3ae82da81403d9cef810ac253b762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Based on your knowledge and your vision of the world, create a description of Open Business. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c86075ee-12c8-4b97-8b51-0c717fc4b1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "### Définition\n",
      "L'Open Business désigne un modèle d'entreprise qui repose sur la transparence, la collaboration et le partage ouvert d'informations, de ressources et de processus. Ce concept vise à créer de la valeur en impliquant un large éventail de parties prenantes, y compris les clients, les partenaires et même les concurrents, dans le développement et l'amélioration des produits et services.\n",
      "\n",
      "### Présentation\n",
      "L'Open Business se distingue par son approche participative et inclusive, qui remet en question les structures hiérarchiques traditionnelles et les pratiques commerciales cloisonnées. Les entreprises adoptant ce modèle favorisent la co-création et l'innovation ouverte, en s'appuyant sur des plateformes collaboratives et des réseaux de partenaires. Cela peut inclure l'utilisation de logiciels open source, la publication de données ouvertes, et l'engagement actif avec les communautés d'utilisateurs pour recueillir des idées et des retours d'expérience.\n",
      "\n",
      "### Description de l'Usage\n",
      "L'Open Business est utilisé par les entreprises pour stimuler l'innovation, améliorer l'efficacité opérationnelle et renforcer la fidélité des clients. En partageant ouvertement des informations et en collaborant avec des parties externes, les entreprises peuvent accélérer le développement de nouveaux produits, réduire les coûts de recherche et développement, et s'adapter plus rapidement aux changements du marché. Les clients, quant à eux, bénéficient de produits et services mieux adaptés à leurs besoins, grâce à leur participation directe au processus de création.\n",
      "\n",
      "### Paysage\n",
      "Le paysage de l'Open Business est varié et en pleine expansion, englobant des entreprises de toutes tailles et de divers secteurs, allant de la technologie à l'agriculture. Des géants de la technologie comme IBM et Google ont adopté des pratiques d'Open Business, tout comme de nombreuses startups et PME. Les plateformes numériques, les réseaux sociaux et les communautés en ligne jouent un rôle crucial en facilitant la collaboration et le partage d'informations. Les initiatives gouvernementales et les politiques de soutien à l'innovation ouverte contribuent également à façonner ce paysage dynamique.\n",
      "\n",
      "### Histoire\n",
      "L'histoire de l'Open Business est étroitement liée à l'évolution des technologies de l'information et de la communication, qui ont permis de nouvelles formes de collaboration et de partage. Le mouvement open source, qui a émergé dans les années 1980 et 1990, a été un précurseur important, démontrant les avantages de la collaboration ouverte dans le développement de logiciels. Au fil des décennies, le concept d'Open Business s'est élargi pour inclure d'autres domaines, tels que l'open data et l'open innovation. Aujourd'hui, l'Open Business est reconnu comme un moteur clé de l'innovation et de la compétitivité dans l'économie mondiale."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "89855a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the previous sections.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9983d6489a6426a8eea95194551306f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Based on your knowledge and your vision of the world, create a description of Open Banking. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0184336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "### Définition\n",
      "L'Open Banking désigne un système bancaire qui permet le partage sécurisé des données financières des clients entre différentes institutions financières et prestataires de services tiers, avec le consentement explicite des clients. Ce concept vise à favoriser l'innovation et la concurrence dans le secteur financier en ouvrant l'accès aux données bancaires traditionnellement détenues par les banques.\n",
      "\n",
      "### Présentation\n",
      "L'Open Banking se caractérise par l'utilisation d'interfaces de programmation d'applications (API) qui permettent aux banques et aux prestataires tiers d'accéder aux données financières des clients de manière sécurisée et standardisée. Ce modèle encourage la création de nouveaux services financiers personnalisés, tels que des applications de gestion de finances personnelles, des solutions de paiement innovantes, et des offres de crédit sur mesure. L'Open Banking repose sur des principes de transparence, de sécurité et de consentement éclairé des clients.\n",
      "\n",
      "### Description de l'Usage\n",
      "L'Open Banking est utilisé par les consommateurs pour bénéficier de services financiers plus personnalisés et compétitifs. Les clients peuvent agréger leurs comptes bancaires sur une seule plateforme, obtenir des recommandations financières basées sur leurs habitudes de dépenses, et accéder à des offres de crédit plus avantageuses. Les entreprises, quant à elles, peuvent utiliser l'Open Banking pour améliorer l'expérience client, développer de nouveaux produits financiers, et optimiser leurs processus internes grâce à une meilleure compréhension des données clients.\n",
      "\n",
      "### Paysage\n",
      "Le paysage de l'Open Banking est en pleine expansion, avec une adoption croissante dans de nombreux pays à travers le monde. En Europe, la directive sur les services de paiement (PSD2) a été un catalyseur majeur, obligeant les banques à ouvrir leurs données à des tiers agréés. D'autres régions, comme l'Amérique du Nord et l'Asie-Pacifique, suivent également cette tendance avec des initiatives similaires. Le paysage est composé de banques traditionnelles, de fintechs, de régulateurs et de développeurs de technologies, tous collaborant pour créer un écosystème financier plus ouvert et interconnecté.\n",
      "\n",
      "### Histoire\n",
      "L'histoire de l'Open Banking est relativement récente, prenant son essor au début du 21e siècle avec l'émergence des fintechs et la digitalisation croissante des services financiers. La directive PSD2, adoptée par l'Union européenne en 2015, a marqué un tournant décisif en établissant un cadre réglementaire pour l'Open Banking. Depuis lors, de nombreux pays ont adopté des réglementations similaires pour encourager l'innovation et la concurrence dans le secteur bancaire. Aujourd'hui, l'Open Banking est reconnu comme un levier essentiel pour transformer le paysage financier mondial, en mettant l'accent sur l'expérience client et l'innovation technologique."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "94929c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Based on your knowledge and your vision of the world, create a description of Open Design. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Design. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Design. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the previous sections.\n",
      "Condensed question: Based on your knowledge and your vision of the world, create a description of Open Design. It needs 5 parts: a definition, a presentation, a usage description, a landscape, and history. Please imitate the writing style of the previous sections.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2ffe4378cf430a8cf56c2824917404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "> Querying with idx: 9d1d3368-aed1-43da-b64d-0bdba0439f8b: Comprendre l'objectif de la visualisation. Avoir une première idée de ce que ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: a7f04498-74a7-4a8f-ba33-35f9cec1cfbb: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Based on your knowledge and your vision of the world, create a description of Open Design. It needs 5 parts : a definition, a presentation, a usage description, a landscape and history. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8d5eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "### Définition\n",
      "L'Open Design désigne une approche de conception qui encourage le partage libre et collaboratif des plans, des idées et des processus de création. Ce concept permet à des designers, ingénieurs et créateurs du monde entier de contribuer, modifier et améliorer des projets de manière ouverte, souvent en utilisant des licences qui permettent la redistribution et la modification des œuvres.\n",
      "\n",
      "### Présentation\n",
      "L'Open Design se caractérise par sa transparence et son inclusivité, permettant à toute personne intéressée de participer au processus de conception. Les projets d'Open Design sont souvent hébergés sur des plateformes en ligne où les fichiers de conception, les instructions de fabrication et les spécifications techniques sont accessibles à tous. Cette approche favorise l'innovation collective et la résolution de problèmes en s'appuyant sur l'intelligence et la créativité de communautés diversifiées.\n",
      "\n",
      "### Description de l'Usage\n",
      "L'Open Design est utilisé dans divers domaines, allant de l'architecture et du design industriel à la mode et à l'électronique. Les designers peuvent collaborer avec des pairs à travers le monde pour développer des produits plus durables, fonctionnels et esthétiques. Les entreprises peuvent adopter l'Open Design pour réduire les coûts de développement, accélérer le temps de mise sur le marché et répondre plus efficacement aux besoins des clients. Les consommateurs, quant à eux, bénéficient de produits personnalisés et innovants, souvent à des prix plus abordables.\n",
      "\n",
      "### Paysage\n",
      "Le paysage de l'Open Design est dynamique et en pleine croissance, soutenu par une communauté mondiale de créateurs, de makerspaces, de fab labs et de plateformes en ligne dédiées. Des initiatives comme OpenDesk pour le mobilier ou Arduino pour l'électronique illustrent la diversité des applications de l'Open Design. Les technologies numériques, telles que l'impression 3D et les logiciels de conception assistée par ordinateur (CAO), jouent un rôle crucial en facilitant la création et le partage de designs ouverts. Les collaborations entre designers, entreprises et institutions académiques enrichissent également ce paysage.\n",
      "\n",
      "### Histoire\n",
      "L'histoire de l'Open Design est intimement liée à l'évolution des mouvements open source et DIY (Do It Yourself). Dans les années 2000, l'essor des technologies numériques et des plateformes de partage a permis aux designers de collaborer plus facilement à l'échelle mondiale. Des projets emblématiques, comme le développement de l'Arduino en 2005, ont démontré le potentiel de l'Open Design pour transformer la manière dont les produits sont conçus et fabriqués. Aujourd'hui, l'Open Design continue de gagner en popularité, promouvant une culture de l'innovation ouverte et de la collaboration créative dans de nombreux secteurs."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ffb78d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74a302-bb28-4bf8-9103-1f62750a5fc0",
   "metadata": {},
   "source": [
    "## Sum-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d81f7480-9d62-4952-948e-19e089d9da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = memory.get_all()\n",
    "\n",
    "# Assuming chat_history is available and contains your messages\n",
    "assistant_messages = [\n",
    "    message.content \n",
    "    for message in chat_history \n",
    "    if message.role == MessageRole.ASSISTANT  # Compare with the enum directly\n",
    "]\n",
    "\n",
    "\n",
    "output_filename = r\"/Users/arthursarazin/Documents/coreandgraphs/graphandopenmodels/output.md\"\n",
    "# Write to a Markdown file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for msg in assistant_messages:\n",
    "        f.write(msg + \"\\n\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
